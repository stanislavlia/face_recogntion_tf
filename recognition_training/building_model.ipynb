{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3161046-0592-4810-a0d6-d1190d0786c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Flatten\n",
    "from keras import Model\n",
    "import keras\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e55fa5-78a7-45b8-a76a-b693ce7126c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_embedding_generator(k_layers_to_tune=10):\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50V2(weights=\"imagenet\", \n",
    "                                                      input_shape=(100, 100, 3),\n",
    "                                                      include_top = False)\n",
    "\n",
    "    for l in base_model.layers[:-k_layers_to_tune]:\n",
    "        l.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation=\"sigmoid\")(x)\n",
    "    #x = tf.nn.l2_normalize(x, axis=1)\n",
    "    \n",
    "    embedding_model = Model(base_model.input, x, name=\"Embedding\")\n",
    "\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7fa1d9-9703-4302-8b22-d9a33dbe66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = build_embedding_generator(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a703f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.load_weights(\"embeddings_resnet50_bigmargin.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6dfd254a-e47c-4b7c-acd0-b06a50047295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Embedding\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 106, 106, 3)          0         ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 50, 50, 64)           9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 52, 52, 64)           0         ['conv1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 25, 25, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (Ba  (None, 25, 25, 64)           256       ['pool1_pool[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (  (None, 25, 25, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 25, 25, 64)           4096      ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPa  (None, 27, 27, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 25, 25, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 25, 25, 256)          16640     ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 25, 25, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)      (None, 25, 25, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
      "                                                                     'conv2_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (Ba  (None, 25, 25, 256)          1024      ['conv2_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (  (None, 25, 25, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 25, 25, 64)           16384     ['conv2_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPa  (None, 27, 27, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 25, 25, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 25, 25, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)      (None, 25, 25, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (Ba  (None, 25, 25, 256)          1024      ['conv2_block2_out[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (  (None, 25, 25, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 25, 25, 64)           16384     ['conv2_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPa  (None, 27, 27, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 13, 13, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 13, 13, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 13, 13, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooli  (None, 13, 13, 256)          0         ['conv2_block2_out[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 13, 13, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)      (None, 13, 13, 256)          0         ['max_pooling2d_24[0][0]',    \n",
      "                                                                     'conv2_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (Ba  (None, 13, 13, 256)          1024      ['conv2_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (  (None, 13, 13, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 13, 13, 128)          32768     ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 13, 13, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 13, 13, 512)          131584    ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 13, 13, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)      (None, 13, 13, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
      "                                                                     'conv3_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (Ba  (None, 13, 13, 512)          2048      ['conv3_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (  (None, 13, 13, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 13, 13, 128)          65536     ['conv3_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 13, 13, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 13, 13, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)      (None, 13, 13, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (Ba  (None, 13, 13, 512)          2048      ['conv3_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (  (None, 13, 13, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 13, 13, 128)          65536     ['conv3_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 13, 13, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 13, 13, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)      (None, 13, 13, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (Ba  (None, 13, 13, 512)          2048      ['conv3_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (  (None, 13, 13, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 13, 13, 128)          65536     ['conv3_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 7, 7, 128)            147456    ['conv3_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 7, 7, 128)            512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 7, 7, 128)            0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_25 (MaxPooli  (None, 7, 7, 512)            0         ['conv3_block3_out[0][0]']    \n",
      " ng2D)                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 7, 7, 512)            66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)      (None, 7, 7, 512)            0         ['max_pooling2d_25[0][0]',    \n",
      "                                                                     'conv3_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (Ba  (None, 7, 7, 512)            2048      ['conv3_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (  (None, 7, 7, 512)            0         ['conv4_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 7, 7, 256)            131072    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 7, 7, 1024)           525312    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block1_0_conv[0][0]', \n",
      "                                                                     'conv4_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block3_preact_relu[0][\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block5_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block5_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block5_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block5_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block5_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block5_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block6_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block6_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block6_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 4, 4, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooli  (None, 4, 4, 1024)           0         ['conv4_block5_out[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)      (None, 4, 4, 1024)           0         ['max_pooling2d_26[0][0]',    \n",
      "                                                                     'conv4_block6_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (Ba  (None, 4, 4, 1024)           4096      ['conv4_block6_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (  (None, 4, 4, 1024)           0         ['conv5_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 4, 4, 512)            524288    ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 4, 4, 2048)           2099200   ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_0_conv[0][0]', \n",
      "                                                                     'conv5_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block2_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalizatio  (None, 4, 4, 2048)           8192      ['conv5_block3_out[0][0]']    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " post_relu (Activation)      (None, 4, 4, 2048)           0         ['post_bn[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8  (None, 2048)                 0         ['post_relu[0][0]']           \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)         (None, 2048)                 0         ['global_average_pooling2d_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 512)                  1049088   ['flatten_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 512)                  2048      ['dense_24[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 512)                  0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_25 (Dense)            (None, 256)                  131328    ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 256)                  1024      ['dense_25[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 128)                  32896     ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24781184 (94.53 MB)\n",
      "Trainable params: 2269568 (8.66 MB)\n",
      "Non-trainable params: 22511616 (85.88 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b32abd-e93e-48e5-9a71-7b4501555654",
   "metadata": {},
   "source": [
    "### Custom layers & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe9b826-f4ce-4816-9944-6d09e260a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "\n",
    "        \n",
    "        anchor_pos_distance = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "        anchor_neg_distance = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "\n",
    "        return (anchor_pos_distance, anchor_neg_distance)\n",
    "\n",
    "\n",
    "def build_siamesenetwork(embedding_model):\n",
    "\n",
    "    anchor_input = keras.layers.Input(name=\"anchor\", shape=(100, 100, 3))\n",
    "    pos_input = keras.layers.Input(name=\"positive\", shape=(100, 100, 3))\n",
    "    neg_input = keras.layers.Input(name=\"negative\", shape=(100, 100, 3))\n",
    "\n",
    "    distances = DistanceLayer()(\n",
    "        embedding_model(anchor_input),\n",
    "        embedding_model(pos_input),\n",
    "        embedding_model(neg_input)\n",
    "    )\n",
    "\n",
    "    siamese_network = Model(\n",
    "            inputs=[anchor_input, pos_input, neg_input],\n",
    "            outputs=distances\n",
    "    )\n",
    "\n",
    "    return siamese_network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2d12c00-0c07-4675-ac12-5e73ac436bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(f(A) - f(P) - f(A) - f(N) + margin, 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    \n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\" : self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        loss = ap_distance - an_distance\n",
    "        #loss = an_distance - ap_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\" : self.loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "\n",
    "        return [self.loss_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1ac9532f-bec9-47a6-81aa-9ee69652578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "siam_net = build_siamesenetwork(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c8ce1e88-9b36-4db6-8be6-2a9da2bd6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "siam_model = SiameseModel(siam_net, margin=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2daa3-2460-4dfe-b21a-8bcb7e35e27d",
   "metadata": {},
   "source": [
    "## UTILS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45cc794-63dd-464f-a4c1-0a339041d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201f863a-9653-4eb9-a53d-2c31fb77a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMGS = \"../images/\"\n",
    "\n",
    "triplets_df = pd.read_csv(\"../triplets.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_csv_line(line):\n",
    "    columns = ['anchor', 'id1', 'pos', 'id2', 'neg', 'id3']\n",
    "    \n",
    "    # Decode the CSV line\n",
    "    record_defaults = [''] * 6  # All fields are strings\n",
    "    parsed_line = tf.io.decode_csv(line, record_defaults)\n",
    "    parsed_line = dict(zip(columns, parsed_line))\n",
    "    return parsed_line\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [100, 100])\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def create_triplet_dataset(csv_file_path, batch_size=32):\n",
    "    dataset = tf.data.TextLineDataset(csv_file_path)\n",
    "    # Skip the header line\n",
    "    dataset = dataset.skip(1)\n",
    "    \n",
    "    # Parse each line\n",
    "    dataset = dataset.map(lambda line: parse_csv_line(line))\n",
    "    # Load and preprocess the images\n",
    "    def load_images(parsed_line):\n",
    "\n",
    "        base_path = tf.constant(PATH_TO_IMGS)\n",
    "        \n",
    "        anchor_path = tf.strings.join([base_path, parsed_line['anchor']], separator='')\n",
    "        pos_path = tf.strings.join([base_path, parsed_line['pos']], separator='')\n",
    "        neg_path = tf.strings.join([base_path, parsed_line['neg']], separator='')\n",
    "\n",
    "        \n",
    "        anchor = load_and_preprocess_image(anchor_path)\n",
    "        pos = load_and_preprocess_image(pos_path)\n",
    "        neg = load_and_preprocess_image(neg_path)\n",
    "        return anchor, pos, neg\n",
    "\n",
    "    \n",
    "    dataset = dataset.map(load_images)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ce5a636-4cfe-4191-9efe-98d889f51af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 22:06:08.297990: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 120000000 exceeds 10% of free system memory.\n",
      "2024-03-07 22:06:08.298195: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 120000000 exceeds 10% of free system memory.\n",
      "2024-03-07 22:06:08.298239: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 120000000 exceeds 10% of free system memory.\n",
      "2024-03-07 22:06:09.209362: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 120000000 exceeds 10% of free system memory.\n",
      "2024-03-07 22:06:09.243046: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 120000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "dataset = create_triplet_dataset(\"../triplets.csv\", batch_size=1000)\n",
    "\n",
    "\n",
    "batch = next(iter(dataset.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9e6ebc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveEmbeddingModelCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_path, model_to_save):\n",
    "        super(SaveEmbeddingModelCallback, self).__init__()\n",
    "        self.save_path = save_path  # Directory where you want to save your model\n",
    "        self.model_to_save = model_to_save  # The model instance you want to save\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Called at the end of an epoch.\n",
    "        \n",
    "        Arguments:\n",
    "            epoch: integer, index of epoch.\n",
    "            logs: dict, metric results for this training epoch, and for the\n",
    "                  validation epoch if validation is performed.\n",
    "        \"\"\"\n",
    "        # Define file path; you could also include epoch in the filename if you wish\n",
    "        file_path = os.path.join(self.save_path, f'embedding_model_epoch_{epoch+1}.h5')\n",
    "        \n",
    "        # Save the model\n",
    "        self.model_to_save.save(file_path)\n",
    "        print(f'\\nModel saved to {file_path} at the end of epoch {epoch+1}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_embedding = SaveEmbeddingModelCallback(save_path=\"emb_checkpoints/\", model_to_save=embedding_model)\n",
    "\n",
    "\n",
    "# model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=checkpoint_filepath,\n",
    "#     save_weights_only=True,  # Set to False to save the entire model     # Set to False to save the model after every epoch regardless of performance\n",
    "#     verbose=1                 # Logs a message whenever a model is save9d\n",
    "# )\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=\"logs/\", update_freq=\"batch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7baf352-6412-41ed-8e49-202f96a71ea5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "    681/Unknown - 1736s 3s/step - loss: 13.9388WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_1.h5 at the end of epoch 1\n",
      "681/681 [==============================] - 1737s 3s/step - loss: 13.9388\n",
      "Epoch 2/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 10.3626WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_2.h5 at the end of epoch 2\n",
      "681/681 [==============================] - 1703s 3s/step - loss: 10.3626\n",
      "Epoch 3/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 9.5332WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_3.h5 at the end of epoch 3\n",
      "681/681 [==============================] - 1705s 3s/step - loss: 9.5332\n",
      "Epoch 4/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 9.0014WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_4.h5 at the end of epoch 4\n",
      "681/681 [==============================] - 1706s 3s/step - loss: 9.0014\n",
      "Epoch 5/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 8.5802WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_5.h5 at the end of epoch 5\n",
      "681/681 [==============================] - 1722s 3s/step - loss: 8.5802\n",
      "Epoch 6/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 8.2308WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_6.h5 at the end of epoch 6\n",
      "681/681 [==============================] - 1714s 3s/step - loss: 8.2308\n",
      "Epoch 7/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 7.9233WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_7.h5 at the end of epoch 7\n",
      "681/681 [==============================] - 1716s 3s/step - loss: 7.9233\n",
      "Epoch 8/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 7.6459WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_8.h5 at the end of epoch 8\n",
      "681/681 [==============================] - 1703s 3s/step - loss: 7.6459\n",
      "Epoch 9/30\n",
      "681/681 [==============================] - ETA: 0s - loss: 7.3894WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "\n",
      "Model saved to emb_checkpoints/embedding_model_epoch_9.h5 at the end of epoch 9\n",
      "681/681 [==============================] - 1717s 3s/step - loss: 7.3894\n",
      "Epoch 10/30\n",
      "309/681 [============>.................] - ETA: 15:38 - loss: 7.1146"
     ]
    }
   ],
   "source": [
    "siam_model.compile(optimizer=keras.optimizers.Adam(0.00001), \n",
    "                   )\n",
    "\n",
    "try:\n",
    "    siam_model.fit(dataset, \n",
    "                   epochs=30,\n",
    "                   callbacks=[save_embedding, tensorboard]\n",
    "                   )\n",
    "\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Trainig is interrupted\")\n",
    "embedding_model.save_weights(\"embeddings_resnet50_bigmargin.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb6a87",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed4f0fb4-53fd-4f20-a63e-6a4e62a816b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 39s 1s/step\n",
      "32/32 [==============================] - 42s 1s/step\n",
      "32/32 [==============================] - 43s 1s/step\n"
     ]
    }
   ],
   "source": [
    "anch_embds = embedding_model.predict(batch[0])\n",
    "pos_embds = embedding_model.predict(batch[1])\n",
    "neg_embds = embedding_model.predict(batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5c58f9e-0738-4492-b3fe-8142b4e8684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim = keras.metrics.CosineSimilarity()\n",
    "\n",
    "pos_cossims = np.array([float(cossim(anch_embds[i], pos_embds[i])) for i in range(1000)])\n",
    "neg_cossims = np.array([float(cossim(anch_embds[i], neg_embds[i])) for i in range(1000)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8999eaa3-51b3-441c-bc6b-c0a39be12855",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = tf.norm(anch_embds - pos_embds, axis=-1).numpy()\n",
    "\n",
    "d_n = tf.norm(anch_embds - neg_embds, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1cef4e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.331859 , 3.822402 , 7.4869804, 7.9824157, 6.9791803, 4.157101 ,\n",
       "       4.748054 , 7.60505  , 6.647621 , 8.024212 , 6.1609073, 4.2906566,\n",
       "       7.2021766, 3.6560526, 4.2341213, 7.102468 , 4.8108253, 6.289505 ,\n",
       "       6.678449 , 7.2843127, 6.6795955, 2.7505302, 6.2519765, 4.7139964,\n",
       "       7.5374007, 8.098869 , 3.6940825, 5.60019  , 5.5409393, 6.343992 ,\n",
       "       5.008264 , 5.3003726, 7.108181 , 8.170531 , 7.3729243, 5.743864 ,\n",
       "       6.9612627, 6.9245143, 2.872502 , 6.944873 , 9.075326 , 6.9429326,\n",
       "       4.6678824, 3.9290237, 2.4809887, 6.314619 , 6.0107236, 6.264238 ,\n",
       "       8.179631 , 8.302161 , 5.725311 , 5.4840736, 6.5914507, 7.2758865,\n",
       "       5.3319273, 7.9294457, 4.9463058, 6.197015 , 6.6108346, 4.3961883,\n",
       "       5.3864903, 5.414202 , 5.7331266, 4.1515627, 1.7420387, 6.306869 ,\n",
       "       5.8097296, 8.468079 , 4.7122655, 4.076252 , 4.4455404, 7.3149834,\n",
       "       7.692631 , 5.5871615, 6.735494 , 6.918128 , 4.0685596, 5.4728713,\n",
       "       5.9931617, 8.150019 , 5.7443743, 4.43379  , 5.210597 , 5.2681713,\n",
       "       5.9638124, 5.9941454, 5.5325766, 6.272364 , 6.715982 , 6.84969  ,\n",
       "       5.0870337, 7.0090103, 7.977251 , 7.0888085, 6.1116214, 3.8604429,\n",
       "       7.2877545, 7.460336 , 5.9974604, 3.8358755, 3.7220306, 5.800895 ,\n",
       "       3.0042872, 7.7444167, 8.1716795, 7.1873536, 5.6128445, 8.519649 ,\n",
       "       6.3895106, 8.30453  , 7.598205 , 8.444566 , 6.1068764, 3.4452896,\n",
       "       5.402069 , 7.8521156, 3.0900624, 3.5481317, 8.675933 , 6.846031 ,\n",
       "       3.007377 , 7.109412 , 3.5968623, 6.3981557, 4.94211  , 4.6250176,\n",
       "       5.0173974, 3.7577145, 6.558435 , 6.029097 , 5.921547 , 7.363939 ,\n",
       "       6.599107 , 3.6563938, 5.581784 , 6.266643 , 6.699076 , 5.6256   ,\n",
       "       3.208724 , 4.4463663, 4.380559 , 4.764297 , 5.7047086, 5.9575152,\n",
       "       5.909081 , 6.7941256, 8.547562 , 5.8673105, 8.417188 , 6.0933213,\n",
       "       6.2891665, 7.868578 , 7.6975837, 6.5771546, 5.506144 , 5.24209  ,\n",
       "       7.488559 , 7.367753 , 3.8402011, 8.647869 , 6.87092  , 7.5767055,\n",
       "       7.6556354, 6.884347 , 4.8213177, 3.8602571, 7.210776 , 5.473613 ,\n",
       "       7.4538016, 6.6711345, 7.4948816, 5.521338 , 7.587078 , 8.442711 ,\n",
       "       7.220486 , 8.680792 , 5.830838 , 6.3523326, 7.8914723, 4.333547 ,\n",
       "       7.6264443, 6.5291014, 8.775092 , 4.632895 , 4.986314 , 3.5680294,\n",
       "       5.0105247, 4.5539107, 5.4665923, 5.905202 , 7.1085973, 6.3529167,\n",
       "       6.069802 , 3.2574503, 2.5233612, 7.8741293, 6.575122 , 7.7203403,\n",
       "       6.6481495, 7.0553446, 5.090442 , 7.3410683, 7.1330953, 6.8747773,\n",
       "       6.1917086, 5.5768495, 4.805402 , 6.213575 , 6.5903716, 7.6165476,\n",
       "       8.405295 , 3.0756407, 7.4072127, 6.554466 , 5.635007 , 7.9216213,\n",
       "       6.0432224, 5.6088133, 7.8670893, 7.1697574, 4.614847 , 5.731855 ,\n",
       "       5.153898 , 7.3332596, 4.723798 , 6.6091647, 6.376797 , 5.2372327,\n",
       "       8.379553 , 7.0064335, 4.5739174, 5.7975855, 6.414761 , 5.0069942,\n",
       "       4.740126 , 1.3287268, 5.615572 , 7.3059998, 8.716087 , 6.2749805,\n",
       "       3.6914637, 5.258184 , 6.4838877, 5.106889 , 4.635765 , 4.257339 ,\n",
       "       3.9642677, 7.681516 , 6.6130457, 4.9015365, 7.4913187, 6.0162544,\n",
       "       6.8251433, 3.5653558, 4.452875 , 5.869115 , 6.6411085, 7.224455 ,\n",
       "       7.442996 , 7.324772 , 5.8423586, 5.4593263, 6.7578335, 6.5293794,\n",
       "       6.1012344, 2.2106256, 7.8356447, 3.6752818, 8.071458 , 7.140481 ,\n",
       "       4.9386964, 5.639875 , 6.8904095, 5.009353 , 7.59428  , 5.986102 ,\n",
       "       4.4556575, 6.632524 , 4.380646 , 7.067311 , 4.4248686, 4.4649806,\n",
       "       7.9597435, 4.144867 , 6.061848 , 2.885403 , 5.907506 , 8.7149935,\n",
       "       6.277793 , 4.6184554, 3.4823596, 5.8230186, 7.6255665, 8.945935 ,\n",
       "       6.5158887, 5.092365 , 5.325899 , 8.266706 , 6.964422 , 2.9689302,\n",
       "       8.695692 , 6.9048276, 5.27895  , 5.2056103, 8.402306 , 6.884274 ,\n",
       "       7.7482357, 6.515535 , 7.4739704, 8.292901 , 7.7739024, 6.889005 ,\n",
       "       2.133893 , 6.5087404, 5.986891 , 8.415773 , 4.8728905, 5.7579727,\n",
       "       8.180727 , 2.4522436, 6.5289125, 6.4852853, 7.510877 , 5.292469 ,\n",
       "       3.5115259, 4.4130416, 6.5435424, 6.338691 , 5.9452424, 7.1755877,\n",
       "       6.0983996, 7.8077497, 8.342859 , 6.6923156, 5.32994  , 5.4877872,\n",
       "       3.5820565, 6.4044795, 6.405922 , 6.026277 , 3.4997687, 4.331353 ,\n",
       "       4.960798 , 8.692255 , 3.3613794, 7.275128 , 6.221347 , 4.4223695,\n",
       "       2.799875 , 7.3058696, 4.658601 , 4.363709 , 5.8490915, 8.407216 ,\n",
       "       4.720911 , 9.237212 , 4.705862 , 4.9403963, 6.1706147, 6.4979677,\n",
       "       8.551434 , 5.1910505, 4.381255 , 9.742177 , 5.252985 , 4.4705687,\n",
       "       6.72878  , 4.1660843, 6.3363147, 6.2390084, 6.736091 , 7.1474195,\n",
       "       7.2171564, 8.647931 , 4.86514  , 7.3174367, 6.063046 , 4.830959 ,\n",
       "       7.9489417, 6.867052 , 5.3786607, 5.895142 , 3.8239844, 7.127399 ,\n",
       "       6.6791587, 6.068333 , 4.974301 , 5.530721 , 8.077485 , 6.571979 ,\n",
       "       6.546218 , 6.337358 , 7.1339183, 3.046755 , 4.201947 , 2.434478 ,\n",
       "       6.10665  , 7.260988 , 6.4680276, 4.8070607, 5.9930444, 4.369346 ,\n",
       "       4.0730243, 4.488515 , 6.4183826, 4.654867 , 3.4956856, 4.7089076,\n",
       "       4.2033   , 4.5309505, 4.3490806, 4.1418066, 4.724082 , 7.441469 ,\n",
       "       7.324701 , 7.834961 , 6.6456485, 5.7844915, 2.7710752, 8.515647 ,\n",
       "       6.427878 , 7.863412 , 7.153655 , 5.1112957, 6.0701203, 6.119438 ,\n",
       "       7.9835396, 6.4647985, 6.62455  , 7.363095 , 6.6953387, 7.8962226,\n",
       "       5.692905 , 6.7594724, 6.9844613, 7.215621 , 4.893682 , 7.00636  ,\n",
       "       5.5882916, 3.5922112, 6.50857  , 6.1199646, 6.9499774, 7.693413 ,\n",
       "       4.0834837, 7.2978024, 5.8851786, 4.9863334, 4.2353497, 4.7921033,\n",
       "       5.450798 , 6.064546 , 5.3417215, 6.6529408, 5.326238 , 5.390418 ,\n",
       "       7.222998 , 4.4247503, 3.7467637, 2.7978756, 4.493684 , 1.4403625,\n",
       "       6.6113715, 8.603024 , 7.170584 , 5.926486 , 6.8568   , 5.526787 ,\n",
       "       8.452485 , 4.613449 , 3.2962902, 7.127862 , 8.712872 , 6.9996095,\n",
       "       7.3247952, 5.580218 , 7.002612 , 6.4370723, 8.214149 , 5.9441214,\n",
       "       6.9964676, 7.709791 , 7.0658073, 5.610191 , 4.2709904, 8.413646 ,\n",
       "       6.7202616, 3.76003  , 7.2205305, 4.4263   , 8.559785 , 8.712756 ,\n",
       "       7.649847 , 8.22297  , 7.033366 , 7.895082 , 4.615145 , 8.57398  ,\n",
       "       4.6207104, 7.016691 , 6.8015804, 7.618031 , 5.23725  , 5.5648217,\n",
       "       6.401647 , 6.803189 , 5.992188 , 4.521917 , 5.271619 , 6.353203 ,\n",
       "       3.8939786, 8.456782 , 7.1345487, 6.0232677, 4.784322 , 7.294324 ,\n",
       "       2.8670533, 3.6112134, 7.1606   , 4.412701 , 5.9017534, 7.8343863,\n",
       "       6.261515 , 7.9196086, 8.974544 , 5.3270297, 1.8727878, 7.8565817,\n",
       "       8.501517 , 7.651259 , 7.2159333, 3.98575  , 5.5373836, 7.7799435,\n",
       "       6.3454027, 6.199959 , 4.6250386, 4.463564 , 5.117919 , 7.2301664,\n",
       "       8.77544  , 8.486958 , 7.951874 , 8.292089 , 6.928914 , 5.9065037,\n",
       "       3.6264093, 6.893754 , 9.318353 , 7.345888 , 6.146062 , 6.1846695,\n",
       "       5.1536126, 6.4657073, 7.8397346, 6.094764 , 4.5917354, 6.9531865,\n",
       "       6.221082 , 7.306867 , 4.4765472, 4.4690347, 6.0777535, 3.7528505,\n",
       "       7.285969 , 2.7691138, 6.028958 , 5.057293 , 4.7727656, 6.2919683,\n",
       "       7.851928 , 6.929807 , 6.291225 , 4.606442 , 7.3261375, 6.535976 ,\n",
       "       7.4071517, 3.4495974, 5.175248 , 6.4774513, 5.009847 , 7.827659 ,\n",
       "       8.102055 , 6.777317 , 7.834168 , 3.938216 , 6.6684046, 7.6234937,\n",
       "       8.110346 , 6.33013  , 5.986339 , 6.479758 , 5.3838625, 5.913294 ,\n",
       "       7.1763244, 4.8849573, 7.1221304, 4.70038  , 7.364731 , 3.9524286,\n",
       "       7.43523  , 7.5088773, 6.9551277, 7.7483425, 7.8082767, 7.709319 ,\n",
       "       6.1568937, 8.341232 , 6.8250613, 6.506016 , 6.725183 , 7.160502 ,\n",
       "       5.6787314, 5.630004 , 8.109788 , 7.14395  , 7.108347 , 2.1177108,\n",
       "       5.719115 , 4.7921653, 6.0995946, 8.21955  , 4.575768 , 4.2970815,\n",
       "       6.4177003, 6.321623 , 8.202702 , 5.7397084, 7.3933597, 6.8498454,\n",
       "       5.164543 , 6.3395367, 8.232293 , 7.074118 , 4.294003 , 8.420309 ,\n",
       "       8.478057 , 7.5875454, 7.202344 , 7.5379167, 4.3676276, 3.7752154,\n",
       "       7.0428047, 6.4352574, 9.532823 , 6.658097 , 5.7646694, 4.038063 ,\n",
       "       3.5516222, 6.882891 , 6.566027 , 8.110505 , 9.409445 , 2.4042485,\n",
       "       5.5883937, 8.023569 , 5.6853924, 7.685716 , 7.0935707, 2.337949 ,\n",
       "       3.8689625, 7.850143 , 4.5441093, 6.9574   , 4.745924 , 8.064869 ,\n",
       "       7.1317177, 5.919644 , 6.163543 , 2.9990027, 9.017965 , 6.334808 ,\n",
       "       6.814801 , 3.479793 , 6.3600273, 7.9378715, 6.3247075, 6.1122804,\n",
       "       4.656316 , 6.550831 , 6.63725  , 8.110944 , 5.964293 , 5.1164575,\n",
       "       6.514585 , 5.245695 , 4.471472 , 6.8070216, 8.324854 , 3.119905 ,\n",
       "       6.7353826, 7.943184 , 5.2443447, 8.733962 , 5.496621 , 4.2326055,\n",
       "       9.0934515, 6.840572 , 7.0589395, 4.324477 , 9.129562 , 6.258905 ,\n",
       "       6.8628445, 6.5171385, 9.094534 , 7.393427 , 6.143857 , 7.0778947,\n",
       "       7.240409 , 4.9533477, 5.4488583, 7.3770256, 5.526582 , 4.6232305,\n",
       "       2.1911032, 5.436343 , 6.1002326, 6.0213556, 3.8931248, 5.919548 ,\n",
       "       4.5857844, 7.130158 , 9.000247 , 6.173869 , 8.218745 , 6.440222 ,\n",
       "       8.895507 , 7.5545917, 9.353415 , 7.3426037, 6.2955604, 8.111669 ,\n",
       "       5.9698567, 7.2022433, 8.300941 , 4.4862614, 7.3741117, 5.33649  ,\n",
       "       6.5807786, 7.7297983, 5.742052 , 6.5179963, 7.6543517, 5.506296 ,\n",
       "       7.6232567, 8.825257 , 4.078762 , 6.354824 , 4.2017097, 8.915873 ,\n",
       "       8.3842945, 8.120456 , 6.393933 , 7.725252 , 6.004842 , 3.3974984,\n",
       "       5.3630686, 5.049442 , 3.5969274, 4.9387755, 7.37084  , 7.208769 ,\n",
       "       6.753388 , 6.477281 , 2.9533029, 2.9315012, 4.176127 , 4.127493 ,\n",
       "       8.561578 , 3.9668217, 5.727046 , 5.3576436, 7.787039 , 6.4025307,\n",
       "       6.668502 , 5.4591002, 7.3894277, 5.9830446, 8.408935 , 5.854614 ,\n",
       "       6.2976866, 5.8821177, 7.183727 , 4.143768 , 7.7948895, 9.457785 ,\n",
       "       4.2646008, 3.1933007, 6.1612663, 5.4102364, 5.7339325, 5.360236 ,\n",
       "       5.6333213, 6.673487 , 7.226662 , 5.455005 , 6.2519016, 6.861064 ,\n",
       "       5.832617 , 6.732549 , 6.8769774, 7.6363063, 2.5462956, 7.388278 ,\n",
       "       7.272915 , 2.688465 , 5.3279157, 6.510655 , 5.7639837, 4.4105725,\n",
       "       6.055721 , 7.366351 , 3.9869719, 8.062806 , 5.409815 , 7.8578043,\n",
       "       3.7400403, 5.308205 , 7.0396495, 3.774618 , 6.397356 , 7.203344 ,\n",
       "       9.166921 , 8.9351635, 5.5575943, 5.011624 , 2.90823  , 4.957327 ,\n",
       "       5.3386087, 3.0929205, 7.462717 , 5.8484793, 5.37078  , 6.4569025,\n",
       "       9.144553 , 7.070983 , 7.3832383, 5.9833603, 6.489354 , 3.5383692,\n",
       "       3.918289 , 6.059465 , 3.0700264, 3.0637364, 8.0393   , 5.2299104,\n",
       "       4.55882  , 5.6012797, 7.8274236, 7.4918356, 3.2772968, 6.7014136,\n",
       "       8.7503195, 7.8928275, 6.650427 , 7.188156 , 7.6337247, 7.180962 ,\n",
       "       8.674556 , 5.386382 , 6.815903 , 5.362596 , 4.553273 , 5.9775286,\n",
       "       8.564462 , 8.011329 , 5.658849 , 5.576305 , 6.267654 , 6.2700067,\n",
       "       8.810716 , 5.8004184, 5.968341 , 7.7039332, 7.6205673, 8.325697 ,\n",
       "       7.087207 , 8.857037 , 8.568174 , 5.694638 , 6.4253383, 7.5054674,\n",
       "       6.0896106, 3.624838 , 6.6219845, 7.2998   , 7.939511 , 7.4202614,\n",
       "       7.6238856, 8.345497 , 5.655082 , 6.988085 , 5.7922373, 6.999179 ,\n",
       "       2.0338912, 8.22974  , 8.106056 , 5.4121456, 3.8581605, 3.017146 ,\n",
       "       7.1718163, 7.0701714, 6.28504  , 7.9623413, 7.2431054, 5.9254856,\n",
       "       5.9661927, 7.0997415, 7.088707 , 7.7119637, 6.9223657, 4.958691 ,\n",
       "       5.729797 , 5.7533355, 4.7440953, 5.3769584, 9.022484 , 7.8074183,\n",
       "       3.0610824, 5.803588 , 6.1384664, 4.878192 , 7.965956 , 5.2804255,\n",
       "       6.143819 , 8.354717 , 3.0622003, 7.477364 , 6.0783534, 7.8591914,\n",
       "       5.741361 , 3.46276  , 7.7407813, 6.4174743, 6.095759 , 6.053726 ,\n",
       "       6.255795 , 3.880536 , 4.404588 , 4.092351 , 6.8918552, 5.600399 ,\n",
       "       4.768832 , 4.9594955, 8.213418 , 6.0211577, 4.619112 , 6.6640153,\n",
       "       5.914192 , 5.5800033, 5.3618507, 5.2963777, 6.3545475, 4.9888263,\n",
       "       5.1199   , 5.430112 , 5.956947 , 6.3796434, 6.106137 , 4.9171367,\n",
       "       6.842997 , 2.615092 , 5.653324 , 6.4224243, 2.6834574, 7.821189 ,\n",
       "       4.5109005, 7.136069 , 6.1302714, 5.694987 , 4.6518507, 2.4446785,\n",
       "       7.7293673, 4.3870416, 6.377682 , 5.3883533, 5.633729 , 6.3089166,\n",
       "       4.2842917, 4.9632683, 4.7667646, 6.514309 , 5.7339563, 5.1490397,\n",
       "       4.947016 , 8.676591 , 7.1092277, 3.0943186, 3.690726 , 8.10052  ,\n",
       "       6.587885 , 3.0966601, 6.389832 , 6.540201 , 7.137843 , 3.303638 ,\n",
       "       7.28939  , 5.249151 , 5.041583 , 5.8665724], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "750db4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.hist(pos_cossims, bins=80, density=True, alpha=0.7, label=\"Positive cossim\")\n",
    "plt.hist(neg_cossims, bins=80, density=True, alpha=0.5, label=\"Negative cossim\")\n",
    "\n",
    "plt.xlim(0.7, 0.9)\n",
    "plt.xticks(np.linspace(0.7, 0.9, 21))\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of Cosine Similarities\")\n",
    "plt.xlabel(\"Cosine Similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96823ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.hist(d_p * d_p, bins=80, density=True, alpha=0.7, label=\"Positive L2 distance\")\n",
    "plt.hist(d_n * d_n, bins=80, density=True, alpha=0.5, label=\"Negative L2 distance\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of Embeddings distances\")\n",
    "plt.xlabel(\"Squared Distance\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf6571da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with t_cossim = 0.819 equals 96.8%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#treshold of cossine sim\n",
    "\n",
    "t = 0.819\n",
    "\n",
    "total_accuracy = (np.sum(pos_cossims >= t) + np.sum(neg_cossims < t)) / 2000\n",
    "\n",
    "\n",
    "print(f\"Accuracy with t_cossim = {t} equals {round(total_accuracy * 100, 5)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ca017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
