{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3161046-0592-4810-a0d6-d1190d0786c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Flatten\n",
    "from keras import Model\n",
    "import keras\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e55fa5-78a7-45b8-a76a-b693ce7126c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_embedding_generator(k_layers_to_tune=10):\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50V2(weights=\"imagenet\", \n",
    "                                                      input_shape=(100, 100, 3),\n",
    "                                                      include_top = False)\n",
    "\n",
    "    for l in base_model.layers[:-k_layers_to_tune]:\n",
    "        l.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation=\"sigmoid\")(x)\n",
    "    #x = tf.nn.l2_normalize(x, axis=1)\n",
    "    \n",
    "    embedding_model = Model(base_model.input, x, name=\"Embedding\")\n",
    "\n",
    "    return embedding_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7fa1d9-9703-4302-8b22-d9a33dbe66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = build_embedding_generator(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfd254a-e47c-4b7c-acd0-b06a50047295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Embedding\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 106, 106, 3)          0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 50, 50, 64)           9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 52, 52, 64)           0         ['conv1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 25, 25, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (Ba  (None, 25, 25, 64)           256       ['pool1_pool[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (  (None, 25, 25, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 25, 25, 64)           4096      ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPa  (None, 27, 27, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 25, 25, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 25, 25, 256)          16640     ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 25, 25, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)      (None, 25, 25, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
      "                                                                     'conv2_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (Ba  (None, 25, 25, 256)          1024      ['conv2_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (  (None, 25, 25, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 25, 25, 64)           16384     ['conv2_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPa  (None, 27, 27, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 25, 25, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 25, 25, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)      (None, 25, 25, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (Ba  (None, 25, 25, 256)          1024      ['conv2_block2_out[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (  (None, 25, 25, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 25, 25, 64)           16384     ['conv2_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 25, 25, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 25, 25, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPa  (None, 27, 27, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 13, 13, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 13, 13, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 13, 13, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 13, 13, 256)          0         ['conv2_block2_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 13, 13, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)      (None, 13, 13, 256)          0         ['max_pooling2d_3[0][0]',     \n",
      "                                                                     'conv2_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (Ba  (None, 13, 13, 256)          1024      ['conv2_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (  (None, 13, 13, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 13, 13, 128)          32768     ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 13, 13, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 13, 13, 512)          131584    ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 13, 13, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)      (None, 13, 13, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
      "                                                                     'conv3_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (Ba  (None, 13, 13, 512)          2048      ['conv3_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (  (None, 13, 13, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 13, 13, 128)          65536     ['conv3_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 13, 13, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 13, 13, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)      (None, 13, 13, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (Ba  (None, 13, 13, 512)          2048      ['conv3_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (  (None, 13, 13, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 13, 13, 128)          65536     ['conv3_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 13, 13, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 13, 13, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)      (None, 13, 13, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (Ba  (None, 13, 13, 512)          2048      ['conv3_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (  (None, 13, 13, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 13, 13, 128)          65536     ['conv3_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 13, 13, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 13, 13, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPa  (None, 15, 15, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 7, 7, 128)            147456    ['conv3_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 7, 7, 128)            512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 7, 7, 128)            0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 512)            0         ['conv3_block3_out[0][0]']    \n",
      " g2D)                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 7, 7, 512)            66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)      (None, 7, 7, 512)            0         ['max_pooling2d_4[0][0]',     \n",
      "                                                                     'conv3_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (Ba  (None, 7, 7, 512)            2048      ['conv3_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (  (None, 7, 7, 512)            0         ['conv4_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 7, 7, 256)            131072    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 7, 7, 1024)           525312    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block1_0_conv[0][0]', \n",
      "                                                                     'conv4_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block3_preact_relu[0][\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block5_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block5_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block5_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block5_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block5_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)      (None, 7, 7, 1024)           0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block5_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (  (None, 7, 7, 1024)           0         ['conv4_block6_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 7, 7, 256)            262144    ['conv4_block6_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPa  (None, 9, 9, 256)            0         ['conv4_block6_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 4, 4, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 1024)           0         ['conv4_block5_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)      (None, 4, 4, 1024)           0         ['max_pooling2d_5[0][0]',     \n",
      "                                                                     'conv4_block6_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (Ba  (None, 4, 4, 1024)           4096      ['conv4_block6_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (  (None, 4, 4, 1024)           0         ['conv5_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 4, 4, 512)            524288    ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 4, 4, 2048)           2099200   ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_0_conv[0][0]', \n",
      "                                                                     'conv5_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block2_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalizatio  (None, 4, 4, 2048)           8192      ['conv5_block3_out[0][0]']    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " post_relu (Activation)      (None, 4, 4, 2048)           0         ['post_bn[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 2048)                 0         ['post_relu[0][0]']           \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 2048)                 0         ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 512)                  1049088   ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 512)                  2048      ['dense_3[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 512)                  0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_4 (Dense)             (None, 256)                  131328    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 256)                  1024      ['dense_4[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 128)                  32896     ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24781184 (94.53 MB)\n",
      "Trainable params: 6734208 (25.69 MB)\n",
      "Non-trainable params: 18046976 (68.84 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b32abd-e93e-48e5-9a71-7b4501555654",
   "metadata": {},
   "source": [
    "### Custom layers & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe9b826-f4ce-4816-9944-6d09e260a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "\n",
    "        \n",
    "        anchor_pos_distance = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "        anchor_neg_distance = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "\n",
    "        return (anchor_pos_distance, anchor_neg_distance)\n",
    "\n",
    "\n",
    "def build_siamesenetwork(embedding_model):\n",
    "\n",
    "    anchor_input = keras.layers.Input(name=\"anchor\", shape=(100, 100, 3))\n",
    "    pos_input = keras.layers.Input(name=\"positive\", shape=(100, 100, 3))\n",
    "    neg_input = keras.layers.Input(name=\"negative\", shape=(100, 100, 3))\n",
    "\n",
    "    distances = DistanceLayer()(\n",
    "        embedding_model(anchor_input),\n",
    "        embedding_model(pos_input),\n",
    "        embedding_model(neg_input)\n",
    "    )\n",
    "\n",
    "    siamese_network = Model(\n",
    "            inputs=[anchor_input, pos_input, neg_input],\n",
    "            outputs=distances\n",
    "    )\n",
    "\n",
    "    return siamese_network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d12c00-0c07-4675-ac12-5e73ac436bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    \n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\" : self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        loss = ap_distance - an_distance\n",
    "        #loss = an_distance - ap_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\" : self.loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "\n",
    "        return [self.loss_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ac9532f-bec9-47a6-81aa-9ee69652578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "siam_net = build_siamesenetwork(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8ce1e88-9b36-4db6-8be6-2a9da2bd6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "siam_model = SiameseModel(siam_net, margin=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2daa3-2460-4dfe-b21a-8bcb7e35e27d",
   "metadata": {},
   "source": [
    "## UTILS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c45cc794-63dd-464f-a4c1-0a339041d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "201f863a-9653-4eb9-a53d-2c31fb77a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMGS = \"../images/\"\n",
    "\n",
    "triplets_df = pd.read_csv(\"../triplets.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_csv_line(line):\n",
    "    columns = ['anchor', 'id1', 'pos', 'id2', 'neg', 'id3']\n",
    "    \n",
    "    # Decode the CSV line\n",
    "    record_defaults = [''] * 6  # All fields are strings\n",
    "    parsed_line = tf.io.decode_csv(line, record_defaults)\n",
    "    parsed_line = dict(zip(columns, parsed_line))\n",
    "    return parsed_line\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    \n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [100, 100])\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def create_triplet_dataset(csv_file_path, batch_size=32):\n",
    "    dataset = tf.data.TextLineDataset(csv_file_path)\n",
    "    # Skip the header line\n",
    "    dataset = dataset.skip(1)\n",
    "    \n",
    "    # Parse each line\n",
    "    dataset = dataset.map(lambda line: parse_csv_line(line))\n",
    "    # Load and preprocess the images\n",
    "    def load_images(parsed_line):\n",
    "\n",
    "        base_path = tf.constant(PATH_TO_IMGS)\n",
    "        \n",
    "        anchor_path = tf.strings.join([base_path, parsed_line['anchor']], separator='')\n",
    "        pos_path = tf.strings.join([base_path, parsed_line['pos']], separator='')\n",
    "        neg_path = tf.strings.join([base_path, parsed_line['neg']], separator='')\n",
    "\n",
    "        \n",
    "        anchor = load_and_preprocess_image(anchor_path)\n",
    "        pos = load_and_preprocess_image(pos_path)\n",
    "        neg = load_and_preprocess_image(neg_path)\n",
    "        return anchor, pos, neg\n",
    "\n",
    "    \n",
    "    dataset = dataset.map(load_images)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce5a636-4cfe-4191-9efe-98d889f51af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_triplet_dataset(\"../triplets.csv\", batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da447811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(24, 100, 100, 3), dtype=float32, numpy=\n",
       " array([[[[1.42117634e-01, 6.76078424e-02, 8.15686025e-03],\n",
       "          [1.96458831e-01, 1.24169417e-01, 5.08117639e-02],\n",
       "          [2.64396071e-01, 1.84388235e-01, 1.03474505e-01],\n",
       "          ...,\n",
       "          [1.83654949e-01, 8.66941139e-02, 2.95372289e-02],\n",
       "          [1.83762282e-01, 9.45662037e-02, 3.96642387e-02],\n",
       "          [2.00941190e-01, 1.14666663e-01, 5.97647056e-02]],\n",
       " \n",
       "         [[2.39372551e-01, 1.62980393e-01, 9.44313705e-02],\n",
       "          [2.80975699e-01, 2.00142741e-01, 1.25750601e-01],\n",
       "          [3.23627442e-01, 2.39019603e-01, 1.54149011e-01],\n",
       "          ...,\n",
       "          [1.83219671e-01, 8.62588286e-02, 2.83019617e-02],\n",
       "          [1.87052429e-01, 9.80963334e-02, 4.10720222e-02],\n",
       "          [2.21176475e-01, 1.35843128e-01, 7.81176463e-02]],\n",
       " \n",
       "         [[2.43137255e-01, 1.59215674e-01, 8.15686211e-02],\n",
       "          [2.90466666e-01, 2.06545100e-01, 1.23054892e-01],\n",
       "          [3.66196066e-01, 2.79117674e-01, 1.86862737e-01],\n",
       "          ...,\n",
       "          [2.14196041e-01, 1.21274427e-01, 5.92156202e-02],\n",
       "          [2.19207853e-01, 1.33349031e-01, 6.84353113e-02],\n",
       "          [2.18039230e-01, 1.35686278e-01, 6.90196157e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[8.00000012e-01, 5.89019597e-01, 4.21176463e-01],\n",
       "          [7.98247039e-01, 5.89603901e-01, 4.26435292e-01],\n",
       "          [7.90882289e-01, 5.83490193e-01, 4.27784294e-01],\n",
       "          ...,\n",
       "          [5.04117757e-02, 4.24509682e-02, 2.97059007e-02],\n",
       "          [5.29647097e-02, 4.41058949e-02, 2.74509806e-02],\n",
       "          [5.64705953e-02, 4.23529521e-02, 2.74509806e-02]],\n",
       " \n",
       "         [[8.02980363e-01, 5.95137239e-01, 4.22588199e-01],\n",
       "          [8.12563062e-01, 6.04719937e-01, 4.38014030e-01],\n",
       "          [8.07364583e-01, 6.01776361e-01, 4.42121506e-01],\n",
       "          ...,\n",
       "          [3.28824222e-02, 3.19412239e-02, 2.32980773e-02],\n",
       "          [3.63773331e-02, 3.39561403e-02, 2.44706105e-02],\n",
       "          [4.00001071e-02, 3.32549438e-02, 2.44706105e-02]],\n",
       " \n",
       "         [[8.00313711e-01, 5.92470586e-01, 4.19921577e-01],\n",
       "          [8.14687848e-01, 6.06844723e-01, 4.40138817e-01],\n",
       "          [8.12662721e-01, 6.07074499e-01, 4.46878433e-01],\n",
       "          ...,\n",
       "          [1.82941221e-02, 1.82941221e-02, 1.04509844e-02],\n",
       "          [2.06290409e-02, 2.05490403e-02, 1.27059035e-02],\n",
       "          [2.08627731e-02, 2.05490403e-02, 1.27059035e-02]]],\n",
       " \n",
       " \n",
       "        [[[2.31921569e-01, 1.57411769e-01, 1.02509804e-01],\n",
       "          [2.45634124e-01, 1.71124309e-01, 1.16021961e-01],\n",
       "          [2.77084321e-01, 1.96103916e-01, 1.41078427e-01],\n",
       "          ...,\n",
       "          [2.30709672e-01, 1.77937135e-01, 1.27997845e-01],\n",
       "          [2.49463573e-01, 1.95820823e-01, 1.61585525e-01],\n",
       "          [2.38470599e-01, 1.87490195e-01, 1.56117648e-01]],\n",
       " \n",
       "         [[2.44980395e-01, 1.72117651e-01, 1.15568630e-01],\n",
       "          [2.48301178e-01, 1.74236074e-01, 1.16026662e-01],\n",
       "          [2.51578420e-01, 1.70598045e-01, 1.13931373e-01],\n",
       "          ...,\n",
       "          [2.25250959e-01, 1.72113702e-01, 1.29468545e-01],\n",
       "          [2.10443750e-01, 1.59908056e-01, 1.26718625e-01],\n",
       "          [1.63294122e-01, 1.13960780e-01, 8.42352957e-02]],\n",
       " \n",
       "         [[2.39215687e-01, 1.72549024e-01, 1.09803930e-01],\n",
       "          [2.30484322e-01, 1.58092171e-01, 9.62058976e-02],\n",
       "          [2.20029414e-01, 1.39803931e-01, 7.96372667e-02],\n",
       "          ...,\n",
       "          [1.95304140e-01, 1.43402159e-01, 1.08304091e-01],\n",
       "          [1.39345333e-01, 9.32276547e-02, 6.70884103e-02],\n",
       "          [9.03921649e-02, 5.00000082e-02, 3.05882394e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[8.55098009e-01, 1.73921436e-01, 1.01764604e-01],\n",
       "          [8.54382396e-01, 1.81794047e-01, 1.06774479e-01],\n",
       "          [8.47000122e-01, 1.84166670e-01, 1.07980438e-01],\n",
       "          ...,\n",
       "          [6.94902003e-01, 7.26274550e-01, 7.38039255e-01],\n",
       "          [6.79433346e-01, 7.12923467e-01, 7.23629415e-01],\n",
       "          [6.78431392e-01, 7.17647076e-01, 7.25490212e-01]],\n",
       " \n",
       "         [[8.72666657e-01, 1.35803908e-01, 7.84313753e-02],\n",
       "          [8.89241993e-01, 1.54182732e-01, 9.62090194e-02],\n",
       "          [8.81396055e-01, 1.47909760e-01, 9.35744792e-02],\n",
       "          ...,\n",
       "          [6.84699953e-01, 7.06778407e-01, 7.21641123e-01],\n",
       "          [6.79019988e-01, 7.04052567e-01, 7.17856467e-01],\n",
       "          [6.72235310e-01, 7.05254912e-01, 7.16196120e-01]],\n",
       " \n",
       "         [[8.78431380e-01, 1.18745096e-01, 7.11372495e-02],\n",
       "          [9.03594911e-01, 1.38583913e-01, 9.09760818e-02],\n",
       "          [9.11543131e-01, 1.40550986e-01, 9.92627442e-02],\n",
       "          ...,\n",
       "          [6.89647079e-01, 7.09254920e-01, 7.24941194e-01],\n",
       "          [6.88440084e-01, 7.08270252e-01, 7.23882377e-01],\n",
       "          [6.85176492e-01, 7.05607831e-01, 7.21019626e-01]]],\n",
       " \n",
       " \n",
       "        [[[1.33882344e-01, 1.22117646e-01, 9.46666673e-02],\n",
       "          [1.48575678e-01, 1.36810973e-01, 1.09359995e-01],\n",
       "          [1.57756865e-01, 1.50698051e-01, 1.27952933e-01],\n",
       "          ...,\n",
       "          [1.53078437e-01, 1.33470595e-01, 1.21705882e-01],\n",
       "          [1.53078437e-01, 1.33470595e-01, 1.21705882e-01],\n",
       "          [1.53078437e-01, 1.33470595e-01, 1.21705882e-01]],\n",
       " \n",
       "         [[1.50666654e-01, 1.38901949e-01, 1.11450978e-01],\n",
       "          [1.58669010e-01, 1.46904305e-01, 1.19453333e-01],\n",
       "          [1.60701960e-01, 1.53643146e-01, 1.30898044e-01],\n",
       "          ...,\n",
       "          [1.57274514e-01, 1.36431381e-01, 1.25078440e-01],\n",
       "          [1.57274514e-01, 1.36431381e-01, 1.25078440e-01],\n",
       "          [1.57274514e-01, 1.36431381e-01, 1.25078440e-01]],\n",
       " \n",
       "         [[1.64019614e-01, 1.52254909e-01, 1.24803923e-01],\n",
       "          [1.63498044e-01, 1.51733339e-01, 1.24282353e-01],\n",
       "          [1.58215672e-01, 1.51156858e-01, 1.28411755e-01],\n",
       "          ...,\n",
       "          [1.60784319e-01, 1.29411772e-01, 1.21568628e-01],\n",
       "          [1.60784319e-01, 1.29411772e-01, 1.21568628e-01],\n",
       "          [1.60784319e-01, 1.29411772e-01, 1.21568628e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[9.23627436e-01, 8.47745061e-01, 7.79705942e-01],\n",
       "          [9.36964691e-01, 8.67564738e-01, 7.96545088e-01],\n",
       "          [8.47588241e-01, 7.88823485e-01, 7.22392142e-01],\n",
       "          ...,\n",
       "          [1.85176492e-01, 1.18666641e-01, 6.47842959e-02],\n",
       "          [1.75988212e-01, 1.24254882e-01, 7.01843500e-02],\n",
       "          [1.67941198e-01, 1.30588308e-01, 7.10785240e-02]],\n",
       " \n",
       "         [[9.35607910e-01, 8.61098111e-01, 7.94431448e-01],\n",
       "          [9.37172592e-01, 8.68623555e-01, 8.04311395e-01],\n",
       "          [8.22243035e-01, 7.62882233e-01, 7.06125438e-01],\n",
       "          ...,\n",
       "          [1.82125568e-01, 1.20619565e-01, 7.29019493e-02],\n",
       "          [1.71920776e-01, 1.26217246e-01, 7.85490423e-02],\n",
       "          [1.68627456e-01, 1.29823506e-01, 8.15294459e-02]],\n",
       " \n",
       "         [[8.61568332e-01, 7.94627190e-01, 7.31744885e-01],\n",
       "          [7.40772545e-01, 6.76916003e-01, 6.14138007e-01],\n",
       "          [5.71355820e-01, 5.17802954e-01, 4.59846050e-01],\n",
       "          ...,\n",
       "          [1.83474585e-01, 1.23054884e-01, 8.50784332e-02],\n",
       "          [1.75392181e-01, 1.27339587e-01, 9.07255262e-02],\n",
       "          [1.72411785e-01, 1.33196101e-01, 9.37059298e-02]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[5.31921566e-01, 5.12313724e-01, 4.88784313e-01],\n",
       "          [5.71421623e-01, 5.51813781e-01, 5.28284371e-01],\n",
       "          [6.06774509e-01, 5.92264712e-01, 5.66186309e-01],\n",
       "          ...,\n",
       "          [6.05972528e-01, 5.70678413e-01, 5.51070571e-01],\n",
       "          [5.90237379e-01, 5.54943264e-01, 5.35335422e-01],\n",
       "          [5.40823519e-01, 5.05529404e-01, 4.85921592e-01]],\n",
       " \n",
       "         [[3.51921558e-01, 3.33137244e-01, 3.07137251e-01],\n",
       "          [4.69306290e-01, 4.50521976e-01, 4.24521983e-01],\n",
       "          [5.79809785e-01, 5.65052927e-01, 5.37039220e-01],\n",
       "          ...,\n",
       "          [5.54784179e-01, 5.19490063e-01, 4.99882281e-01],\n",
       "          [5.96506715e-01, 5.61212599e-01, 5.41604757e-01],\n",
       "          [5.98117650e-01, 5.62823534e-01, 5.43215692e-01]],\n",
       " \n",
       "         [[3.55294108e-01, 3.39607835e-01, 3.04313719e-01],\n",
       "          [4.78441179e-01, 4.62754905e-01, 4.27460790e-01],\n",
       "          [5.41127443e-01, 5.25441170e-01, 4.90147084e-01],\n",
       "          ...,\n",
       "          [5.16088068e-01, 4.80793953e-01, 4.61186111e-01],\n",
       "          [5.95501959e-01, 5.60207844e-01, 5.40600002e-01],\n",
       "          [6.24313712e-01, 5.89019597e-01, 5.69411755e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[9.51372564e-01, 9.33137298e-01, 9.02745128e-01],\n",
       "          [9.58652914e-01, 9.46613729e-01, 9.13123548e-01],\n",
       "          [9.59823549e-01, 9.59627450e-01, 9.24549043e-01],\n",
       "          ...,\n",
       "          [5.09029448e-01, 4.99529421e-01, 5.47676504e-01],\n",
       "          [3.52162659e-01, 3.45678359e-01, 3.97496015e-01],\n",
       "          [1.72941014e-01, 1.71568483e-01, 2.21372381e-01]],\n",
       " \n",
       "         [[9.66156840e-01, 9.52745140e-01, 9.32313740e-01],\n",
       "          [9.74800408e-01, 9.62689817e-01, 9.41607833e-01],\n",
       "          [9.76562738e-01, 9.74994123e-01, 9.51190174e-01],\n",
       "          ...,\n",
       "          [3.67598176e-01, 3.57206047e-01, 4.03088391e-01],\n",
       "          [2.33758882e-01, 2.26261631e-01, 2.77069092e-01],\n",
       "          [1.24862731e-01, 1.18666641e-01, 1.68823510e-01]],\n",
       " \n",
       "         [[9.57686245e-01, 9.45921540e-01, 9.26313698e-01],\n",
       "          [9.66980338e-01, 9.60978031e-01, 9.41370189e-01],\n",
       "          [9.88415718e-01, 9.84658837e-01, 9.64872539e-01],\n",
       "          ...,\n",
       "          [2.15727583e-01, 2.05335408e-01, 2.46476561e-01],\n",
       "          [1.30842388e-01, 1.22999251e-01, 1.73979640e-01],\n",
       "          [7.78039098e-02, 6.99607730e-02, 1.20941162e-01]]],\n",
       " \n",
       " \n",
       "        [[[2.34941170e-01, 2.50627458e-01, 2.93764710e-01],\n",
       "          [2.39925489e-01, 2.64729410e-01, 3.04827422e-01],\n",
       "          [2.49387249e-01, 2.74607837e-01, 3.18284303e-01],\n",
       "          ...,\n",
       "          [2.15897053e-01, 2.46647060e-01, 2.49455884e-01],\n",
       "          [2.14810625e-01, 2.61124462e-01, 2.69576430e-01],\n",
       "          [1.95450976e-01, 2.53921568e-01, 2.65686274e-01]],\n",
       " \n",
       "         [[2.27137253e-01, 2.45999992e-01, 2.85960764e-01],\n",
       "          [2.26802945e-01, 2.52321571e-01, 2.90063709e-01],\n",
       "          [2.48029411e-01, 2.75480390e-01, 3.12578410e-01],\n",
       "          ...,\n",
       "          [1.89950988e-01, 2.17245087e-01, 2.19774514e-01],\n",
       "          [1.08321674e-01, 1.48710981e-01, 1.55456126e-01],\n",
       "          [1.21450976e-01, 1.73176467e-01, 1.86000004e-01]],\n",
       " \n",
       "         [[2.15686277e-01, 2.43137255e-01, 2.74509817e-01],\n",
       "          [2.25411758e-01, 2.52862751e-01, 2.81500012e-01],\n",
       "          [2.45392174e-01, 2.72843152e-01, 3.02892178e-01],\n",
       "          ...,\n",
       "          [2.02107847e-01, 2.20147058e-01, 2.22009823e-01],\n",
       "          [1.26946196e-01, 1.57039404e-01, 1.63514942e-01],\n",
       "          [1.44117653e-01, 1.81960791e-01, 1.95882350e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.07646719e-01, 7.54899234e-02, 7.76467696e-02],\n",
       "          [1.16764367e-01, 8.59752372e-02, 7.90144280e-02],\n",
       "          [1.26764372e-01, 9.88232791e-02, 7.58575574e-02],\n",
       "          ...,\n",
       "          [9.05906856e-01, 9.37279403e-01, 9.80416656e-01],\n",
       "          [9.00588155e-01, 9.31960702e-01, 9.76862729e-01],\n",
       "          [8.94509792e-01, 9.25882339e-01, 9.76862729e-01]],\n",
       " \n",
       "         [[1.95568308e-01, 1.44901708e-01, 1.45960554e-01],\n",
       "          [2.00248733e-01, 1.49582133e-01, 1.45960554e-01],\n",
       "          [2.05382094e-01, 1.60744876e-01, 1.43509567e-01],\n",
       "          ...,\n",
       "          [9.15848017e-01, 9.41495121e-01, 9.87495065e-01],\n",
       "          [9.09843028e-01, 9.36778426e-01, 9.83899057e-01],\n",
       "          [9.03764665e-01, 9.35137212e-01, 9.86117601e-01]],\n",
       " \n",
       "         [[2.47803777e-01, 1.85764596e-01, 1.89333215e-01],\n",
       "          [2.50842988e-01, 1.88803822e-01, 1.89333215e-01],\n",
       "          [2.58637100e-01, 2.03950852e-01, 1.84651837e-01],\n",
       "          ...,\n",
       "          [9.18627441e-01, 9.42156851e-01, 9.89215672e-01],\n",
       "          [9.11157787e-01, 9.36451912e-01, 9.84393120e-01],\n",
       "          [9.02313709e-01, 9.33686256e-01, 9.84666646e-01]]],\n",
       " \n",
       " \n",
       "        [[[8.14117640e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [6.66980371e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [8.51764679e-02, 7.92156812e-03, 6.27450878e-04],\n",
       "          ...,\n",
       "          [2.78117627e-01, 1.97725490e-01, 1.19294114e-01],\n",
       "          [1.82305351e-01, 1.13301493e-01, 6.53173625e-02],\n",
       "          [6.08627424e-02, 4.70588170e-03, 3.13725439e-04]],\n",
       " \n",
       "         [[6.87058866e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [8.01254883e-02, 2.63529434e-03, 0.00000000e+00],\n",
       "          [1.27058834e-01, 3.93725485e-02, 1.39607843e-02],\n",
       "          ...,\n",
       "          [2.72627443e-01, 1.89882353e-01, 1.11921571e-01],\n",
       "          [1.93317398e-01, 1.18384078e-01, 5.49645014e-02],\n",
       "          [1.36000007e-01, 6.44705892e-02, 8.62745102e-03]],\n",
       " \n",
       "         [[6.43137246e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [9.56078470e-02, 1.31764710e-02, 0.00000000e+00],\n",
       "          [1.60784319e-01, 6.94117621e-02, 3.49019580e-02],\n",
       "          ...,\n",
       "          [2.72156864e-01, 1.82745099e-01, 1.03137255e-01],\n",
       "          [1.84078231e-01, 1.04078263e-01, 3.99214588e-02],\n",
       "          [1.39607847e-01, 6.50980473e-02, 1.41176507e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.38431320e-01, 2.22745046e-01, 2.14117616e-01],\n",
       "          [2.45019555e-01, 2.26588205e-01, 2.14117616e-01],\n",
       "          [2.47058839e-01, 2.19607860e-01, 1.98823541e-01],\n",
       "          ...,\n",
       "          [1.08235255e-01, 4.54901606e-02, 3.56862396e-02],\n",
       "          [1.27059013e-01, 5.52942865e-02, 3.72550488e-02],\n",
       "          [1.70980439e-01, 9.64706391e-02, 7.29412287e-02]],\n",
       " \n",
       "         [[2.48000026e-01, 2.32313752e-01, 2.20549047e-01],\n",
       "          [2.51403958e-01, 2.32972577e-01, 2.18462780e-01],\n",
       "          [2.17804104e-01, 1.90353125e-01, 1.68784499e-01],\n",
       "          ...,\n",
       "          [1.32548913e-01, 6.98038116e-02, 5.99998906e-02],\n",
       "          [1.31796062e-01, 6.00313358e-02, 4.19920981e-02],\n",
       "          [1.30039409e-01, 5.55296056e-02, 3.20001952e-02]],\n",
       " \n",
       "         [[2.29019642e-01, 2.13333368e-01, 2.01568663e-01],\n",
       "          [2.34290242e-01, 2.15858862e-01, 2.01349050e-01],\n",
       "          [2.00784326e-01, 1.73333347e-01, 1.51764721e-01],\n",
       "          ...,\n",
       "          [1.35450989e-01, 7.27058873e-02, 6.29019663e-02],\n",
       "          [1.29301891e-01, 5.75371683e-02, 3.94979306e-02],\n",
       "          [1.10745117e-01, 3.62353139e-02, 1.27059035e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(24, 100, 100, 3), dtype=float32, numpy=\n",
       " array([[[[0.8747059 , 0.6864706 , 0.01980392],\n",
       "          [0.8847745 , 0.7024255 , 0.03281569],\n",
       "          [0.88069606, 0.70016664, 0.02964706],\n",
       "          ...,\n",
       "          [0.93241185, 0.75456864, 0.02947058],\n",
       "          [0.92541564, 0.7442823 , 0.03855488],\n",
       "          [0.92882353, 0.74490196, 0.0545098 ]],\n",
       " \n",
       "         [[0.8813726 , 0.6913726 , 0.02411765],\n",
       "          [0.89872164, 0.7101157 , 0.04332548],\n",
       "          [0.87733334, 0.69381374, 0.0257451 ],\n",
       "          ...,\n",
       "          [0.9190392 , 0.7417844 , 0.01709804],\n",
       "          [0.9094059 , 0.730549  , 0.02521566],\n",
       "          [0.91823524, 0.74294114, 0.05      ]],\n",
       " \n",
       "         [[0.9009804 , 0.70098037, 0.03431373],\n",
       "          [0.8738725 , 0.6800687 , 0.01804902],\n",
       "          [0.8953431 , 0.70700985, 0.05068628],\n",
       "          ...,\n",
       "          [0.92602944, 0.7547059 , 0.03240193],\n",
       "          [0.92280394, 0.7495294 , 0.05261762],\n",
       "          [0.92745095, 0.7588235 , 0.07352941]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.38137254, 0.25980392, 0.16862746],\n",
       "          [0.3798235 , 0.2419902 , 0.13842157],\n",
       "          [0.52916664, 0.3576961 , 0.23490196],\n",
       "          ...,\n",
       "          [0.29794127, 0.28916666, 0.23901957],\n",
       "          [0.26389217, 0.3018529 , 0.2593333 ],\n",
       "          [0.24607843, 0.30882353, 0.26862746]],\n",
       " \n",
       "         [[0.3198035 , 0.1809799 , 0.08745045],\n",
       "          [0.36193717, 0.20498998, 0.10696844],\n",
       "          [0.51919603, 0.33550972, 0.21666658],\n",
       "          ...,\n",
       "          [0.24505855, 0.22897997, 0.18407802],\n",
       "          [0.23971549, 0.27030954, 0.23132917],\n",
       "          [0.2637256 , 0.31647062, 0.2805883 ]],\n",
       " \n",
       "         [[0.26137233, 0.11274483, 0.02235269],\n",
       "          [0.34920195, 0.19081564, 0.08555286],\n",
       "          [0.52510786, 0.33404902, 0.21412747],\n",
       "          ...,\n",
       "          [0.189588  , 0.16842124, 0.12541142],\n",
       "          [0.20372137, 0.22262129, 0.18795463],\n",
       "          [0.24058811, 0.2841175 , 0.25254887]]],\n",
       " \n",
       " \n",
       "        [[[0.17949018, 0.11674509, 0.02654901],\n",
       "          [0.26024276, 0.19118392, 0.10414471],\n",
       "          [0.36194214, 0.27282453, 0.18654999],\n",
       "          ...,\n",
       "          [0.22469147, 0.13853455, 0.08350906],\n",
       "          [0.17690939, 0.10231193, 0.05061526],\n",
       "          [0.24137254, 0.17078431, 0.13086274]],\n",
       " \n",
       "         [[0.34003922, 0.27517647, 0.18603922],\n",
       "          [0.32441273, 0.2523839 , 0.16640353],\n",
       "          [0.344001  , 0.253851  , 0.16792059],\n",
       "          ...,\n",
       "          [0.3162382 , 0.21654303, 0.16132732],\n",
       "          [0.31064767, 0.22531433, 0.17615747],\n",
       "          [0.24047059, 0.16776471, 0.1217647 ]],\n",
       " \n",
       "         [[0.28745097, 0.21686272, 0.13058822],\n",
       "          [0.31775686, 0.23911864, 0.15173921],\n",
       "          [0.39974508, 0.30737746, 0.22065686],\n",
       "          ...,\n",
       "          [0.33302495, 0.21980432, 0.16626017],\n",
       "          [0.23797743, 0.13985978, 0.09322155],\n",
       "          [0.26686275, 0.18137257, 0.1364706 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.39901987, 0.44294137, 0.56666684],\n",
       "          [0.20787184, 0.25179332, 0.3755188 ],\n",
       "          [0.11286289, 0.15241677, 0.28289223],\n",
       "          ...,\n",
       "          [0.173196  , 0.25680864, 0.43051955],\n",
       "          [0.19485822, 0.28836796, 0.4676671 ],\n",
       "          [0.10725532, 0.20392193, 0.40137297]],\n",
       " \n",
       "         [[0.30384353, 0.3605494 , 0.4889023 ],\n",
       "          [0.13431986, 0.1910257 , 0.31937864],\n",
       "          [0.07430211, 0.12499913, 0.25936088],\n",
       "          ...,\n",
       "          [0.12721092, 0.22396475, 0.37136582],\n",
       "          [0.14187737, 0.24871124, 0.40527874],\n",
       "          [0.14396033, 0.25164658, 0.438078  ]],\n",
       " \n",
       "         [[0.1999219 , 0.26231405, 0.3917258 ],\n",
       "          [0.07339469, 0.13578683, 0.2651986 ],\n",
       "          [0.04396284, 0.10106087, 0.24058437],\n",
       "          ...,\n",
       "          [0.12043311, 0.23035458, 0.35139388],\n",
       "          [0.18157604, 0.29999816, 0.43550685],\n",
       "          [0.2510585 , 0.3608624 , 0.54517615]]],\n",
       " \n",
       " \n",
       "        [[[0.9174314 , 0.92527455, 0.8821373 ],\n",
       "          [0.9238003 , 0.9316434 , 0.8885062 ],\n",
       "          [0.9252152 , 0.9302152 , 0.89560735],\n",
       "          ...,\n",
       "          [0.27872396, 0.2865671 , 0.23166512],\n",
       "          [0.24422207, 0.2520652 , 0.19716325],\n",
       "          [0.25903922, 0.26688236, 0.21198039]],\n",
       " \n",
       "         [[0.9137255 , 0.9209216 , 0.8797255 ],\n",
       "          [0.9175403 , 0.92473644, 0.88354033],\n",
       "          [0.9206682 , 0.9254902 , 0.8923544 ],\n",
       "          ...,\n",
       "          [0.449118  , 0.45696113, 0.40270624],\n",
       "          [0.35684547, 0.36490214, 0.31054047],\n",
       "          [0.24592157, 0.25505883, 0.20015687]],\n",
       " \n",
       "         [[0.9137255 , 0.91764706, 0.8862745 ],\n",
       "          [0.921175  , 0.9250966 , 0.893724  ],\n",
       "          [0.92186517, 0.92578673, 0.90010047],\n",
       "          ...,\n",
       "          [0.34541884, 0.35326198, 0.30443844],\n",
       "          [0.213048  , 0.22200732, 0.17271467],\n",
       "          [0.17588237, 0.1904902 , 0.13882354]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.87558824, 0.8734314 , 0.78039217],\n",
       "          [0.8696122 , 0.8627073 , 0.77204216],\n",
       "          [0.84568626, 0.8293137 , 0.74764705],\n",
       "          ...,\n",
       "          [0.60362494, 0.38401717, 0.2546054 ],\n",
       "          [0.60521716, 0.38654757, 0.25666666],\n",
       "          [0.60284317, 0.38892156, 0.25666666]],\n",
       " \n",
       "         [[0.8745098 , 0.8745098 , 0.78039217],\n",
       "          [0.87123525, 0.8701546 , 0.77657735],\n",
       "          [0.8549652 , 0.8403936 , 0.75782645],\n",
       "          ...,\n",
       "          [0.60827446, 0.38866666, 0.2592549 ],\n",
       "          [0.6099303 , 0.39161655, 0.26155773],\n",
       "          [0.6039216 , 0.39215687, 0.25882354]],\n",
       " \n",
       "         [[0.8708039 , 0.86709803, 0.7840981 ],\n",
       "          [0.87371826, 0.87001234, 0.7870124 ],\n",
       "          [0.8627652 , 0.84753036, 0.7624691 ],\n",
       "          ...,\n",
       "          [0.6052156 , 0.38931373, 0.26731372],\n",
       "          [0.60737616, 0.39215687, 0.26828685],\n",
       "          [0.6039216 , 0.39215687, 0.25882354]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.74215686, 0.62058824, 0.3970588 ],\n",
       "          [0.8297255 , 0.7081569 , 0.48462746],\n",
       "          [0.7012745 , 0.5797059 , 0.3561765 ],\n",
       "          ...,\n",
       "          [0.89931387, 0.82480407, 0.6036276 ],\n",
       "          [0.9286469 , 0.8541371 , 0.62668616],\n",
       "          [0.8906863 , 0.8161765 , 0.5887255 ]],\n",
       " \n",
       "         [[0.8480392 , 0.7264706 , 0.5029412 ],\n",
       "          [0.8320784 , 0.7105098 , 0.48698038],\n",
       "          [0.74715686, 0.62558824, 0.4020588 ],\n",
       "          ...,\n",
       "          [0.92607814, 0.8486272 , 0.6289213 ],\n",
       "          [0.877647  , 0.80019605, 0.57421565],\n",
       "          [0.86470586, 0.7872549 , 0.5612745 ]],\n",
       " \n",
       "         [[0.6960784 , 0.5745098 , 0.3509804 ],\n",
       "          [0.81384313, 0.6922745 , 0.46874508],\n",
       "          [0.8530392 , 0.7314706 , 0.5079411 ],\n",
       "          ...,\n",
       "          [0.9427449 , 0.857941  , 0.63676447],\n",
       "          [0.9083335 , 0.82352954, 0.60000014],\n",
       "          [0.9406863 , 0.85588235, 0.63235295]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.22892156, 0.57990193, 0.75392157],\n",
       "          [0.23237255, 0.5682549 , 0.74701965],\n",
       "          [0.25480393, 0.5639216 , 0.74764705],\n",
       "          ...,\n",
       "          [0.35107827, 0.6179412 , 0.7575492 ],\n",
       "          [0.32076466, 0.6223138 , 0.78901964],\n",
       "          [0.3112745 , 0.6313726 , 0.8127451 ]],\n",
       " \n",
       "         [[0.2485294 , 0.58235294, 0.7612745 ],\n",
       "          [0.24119608, 0.5620784 , 0.7457451 ],\n",
       "          [0.26019606, 0.55852944, 0.7491176 ],\n",
       "          ...,\n",
       "          [0.35450965, 0.6203922 , 0.75901973],\n",
       "          [0.32723522, 0.62417644, 0.78598046],\n",
       "          [0.3112745 , 0.62892157, 0.80539215]],\n",
       " \n",
       "         [[0.24166666, 0.5710784 , 0.75147057],\n",
       "          [0.2097451 , 0.5318236 , 0.7156667 ],\n",
       "          [0.22147058, 0.5233333 , 0.7139216 ],\n",
       "          ...,\n",
       "          [0.35794103, 0.61833334, 0.7618628 ],\n",
       "          [0.33049014, 0.62743133, 0.7858236 ],\n",
       "          [0.31323528, 0.6308824 , 0.8004902 ]]],\n",
       " \n",
       " \n",
       "        [[[0.06192157, 0.08152942, 0.09721569],\n",
       "          [0.06330745, 0.08291529, 0.09860157],\n",
       "          [0.07255686, 0.0921647 , 0.10785098],\n",
       "          ...,\n",
       "          [0.19866304, 0.20440029, 0.20679642],\n",
       "          [0.14655   , 0.15439314, 0.15047157],\n",
       "          [0.07719608, 0.08503921, 0.08111764]],\n",
       " \n",
       "         [[0.05613726, 0.07450981, 0.08896078],\n",
       "          [0.14648785, 0.16486038, 0.17931136],\n",
       "          [0.16153726, 0.17916864, 0.19510198],\n",
       "          ...,\n",
       "          [0.13793768, 0.14578082, 0.13938865],\n",
       "          [0.09577022, 0.10361335, 0.0972212 ],\n",
       "          [0.09013726, 0.09798039, 0.09158824]],\n",
       " \n",
       "         [[0.05470588, 0.06421569, 0.07803921],\n",
       "          [0.12206274, 0.13157253, 0.14539607],\n",
       "          [0.19368625, 0.20207842, 0.21937253],\n",
       "          ...,\n",
       "          [0.15600029, 0.16384342, 0.15207872],\n",
       "          [0.12743528, 0.13527842, 0.12351372],\n",
       "          [0.12676471, 0.13460785, 0.12284313]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0400983 , 0.06588254, 0.08323555],\n",
       "          [0.04509033, 0.07087457, 0.08822758],\n",
       "          [0.056549  , 0.07056853, 0.09956864],\n",
       "          ...,\n",
       "          [0.38564777, 0.28525558, 0.23427495],\n",
       "          [0.30987057, 0.2113843 , 0.18809801],\n",
       "          [0.3290197 , 0.22911772, 0.21901976]],\n",
       " \n",
       "         [[0.04931362, 0.06354888, 0.09513717],\n",
       "          [0.04539442, 0.05962968, 0.09121796],\n",
       "          [0.04899211, 0.05146266, 0.09555683],\n",
       "          ...,\n",
       "          [0.3665966 , 0.26620442, 0.21737278],\n",
       "          [0.3174949 , 0.21851449, 0.2007937 ],\n",
       "          [0.3372549 , 0.23529412, 0.23137255]],\n",
       " \n",
       "         [[0.06068636, 0.0619216 , 0.10774519],\n",
       "          [0.07104329, 0.0669436 , 0.11810212],\n",
       "          [0.09821985, 0.08067075, 0.14317279],\n",
       "          ...,\n",
       "          [0.35541612, 0.25502393, 0.2071805 ],\n",
       "          [0.30912387, 0.2101435 , 0.19430034],\n",
       "          [0.3056665 , 0.20370573, 0.19978416]]],\n",
       " \n",
       " \n",
       "        [[[0.05431373, 0.03078431, 0.03078431],\n",
       "          [0.07446078, 0.05093137, 0.05093137],\n",
       "          [0.09778921, 0.0742598 , 0.0742598 ],\n",
       "          ...,\n",
       "          [0.26140675, 0.21866167, 0.19307342],\n",
       "          [0.21447934, 0.17930876, 0.15426663],\n",
       "          [0.19607843, 0.16117646, 0.14137255]],\n",
       " \n",
       "         [[0.12176471, 0.09941176, 0.1       ],\n",
       "          [0.11155686, 0.08920392, 0.08979215],\n",
       "          [0.10388235, 0.08097059, 0.08127941],\n",
       "          ...,\n",
       "          [0.27608803, 0.23334296, 0.2071959 ],\n",
       "          [0.206147  , 0.1733235 , 0.14710781],\n",
       "          [0.19137254, 0.16392156, 0.14039215]],\n",
       " \n",
       "         [[0.14411765, 0.12843138, 0.13235295],\n",
       "          [0.10583824, 0.09015197, 0.09407353],\n",
       "          [0.08218137, 0.0627696 , 0.06575981],\n",
       "          ...,\n",
       "          [0.2936763 , 0.2509312 , 0.22264689],\n",
       "          [0.21149985, 0.17836753, 0.15442146],\n",
       "          [0.17254902, 0.14411765, 0.12352941]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.41568628, 0.4117647 , 0.44313726],\n",
       "          [0.56611764, 0.5621961 , 0.5935686 ],\n",
       "          [0.49139705, 0.48375002, 0.5132598 ],\n",
       "          ...,\n",
       "          [0.6605635 , 0.64487725, 0.7032351 ],\n",
       "          [0.6205149 , 0.60112274, 0.66118157],\n",
       "          [0.6843137 , 0.65686274, 0.71960783]],\n",
       " \n",
       "         [[0.70019853, 0.68961024, 0.71764946],\n",
       "          [0.81893104, 0.8083428 , 0.836382  ],\n",
       "          [0.64469224, 0.63354516, 0.6613049 ],\n",
       "          ...,\n",
       "          [0.7376916 , 0.7253387 , 0.79082894],\n",
       "          [0.8036105 , 0.78965175, 0.8532272 ],\n",
       "          [0.6980397 , 0.6805888 , 0.74000055]],\n",
       " \n",
       "         [[0.4329396 , 0.42117488, 0.44862586],\n",
       "          [0.6701383 , 0.6583736 , 0.6858246 ],\n",
       "          [0.56751424, 0.55574954, 0.5832005 ],\n",
       "          ...,\n",
       "          [0.6247449 , 0.6129802 , 0.67964685],\n",
       "          [0.70079625, 0.68779624, 0.75199234],\n",
       "          [0.6539213 , 0.63823503, 0.69705856]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(24, 100, 100, 3), dtype=float32, numpy=\n",
       " array([[[[1.67450979e-01, 1.47843137e-01, 1.36078432e-01],\n",
       "          [1.44809306e-01, 1.25201464e-01, 1.13436766e-01],\n",
       "          [1.23431370e-01, 1.03823520e-01, 9.20588151e-02],\n",
       "          ...,\n",
       "          [1.88164264e-01, 1.18458383e-01, 1.10321127e-01],\n",
       "          [1.68896556e-01, 1.02292188e-01, 9.08857659e-02],\n",
       "          [1.65882349e-01, 1.07058823e-01, 8.74509737e-02]],\n",
       " \n",
       "         [[1.42352954e-01, 1.22745104e-01, 1.10980399e-01],\n",
       "          [1.22164704e-01, 1.02556862e-01, 9.07921568e-02],\n",
       "          [1.05933823e-01, 8.63259807e-02, 7.40980357e-02],\n",
       "          ...,\n",
       "          [1.99286804e-01, 1.41345620e-01, 1.29580915e-01],\n",
       "          [1.83732316e-01, 1.26042604e-01, 1.11791112e-01],\n",
       "          [1.76862746e-01, 1.19803920e-01, 9.93137285e-02]],\n",
       " \n",
       "         [[1.04411766e-01, 8.48039240e-02, 7.30392188e-02],\n",
       "          [9.95048955e-02, 7.98970535e-02, 6.81323484e-02],\n",
       "          [1.03725493e-01, 8.41176510e-02, 7.02941120e-02],\n",
       "          ...,\n",
       "          [1.95502490e-01, 1.45012289e-01, 1.31777003e-01],\n",
       "          [1.76134735e-01, 1.25504822e-01, 1.09335668e-01],\n",
       "          [1.61764711e-01, 1.10784315e-01, 8.72549042e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2.35294122e-02, 3.13725509e-02, 1.17647061e-02],\n",
       "          [3.19411792e-02, 3.69803943e-02, 1.73725504e-02],\n",
       "          [3.42647061e-02, 3.14950980e-02, 1.31740188e-02],\n",
       "          ...,\n",
       "          [1.95551485e-01, 1.52414218e-01, 1.44571081e-01],\n",
       "          [1.92573547e-01, 1.48318633e-01, 1.42710820e-01],\n",
       "          [1.96078435e-01, 1.49019614e-01, 1.49019614e-01]],\n",
       " \n",
       "         [[2.65686028e-02, 3.44117396e-02, 1.48038976e-02],\n",
       "          [3.49803716e-02, 4.00195867e-02, 1.82387196e-02],\n",
       "          [3.58112417e-02, 3.14975157e-02, 1.09092994e-02],\n",
       "          ...,\n",
       "          [2.69668669e-01, 2.17413843e-01, 2.09722668e-01],\n",
       "          [2.77823061e-01, 2.27049112e-01, 2.19268292e-01],\n",
       "          [2.83430874e-01, 2.36372054e-01, 2.36372054e-01]],\n",
       " \n",
       "         [[4.55881469e-02, 5.34312837e-02, 3.38234380e-02],\n",
       "          [4.88126837e-02, 5.38518988e-02, 3.14401314e-02],\n",
       "          [4.80391644e-02, 4.37254347e-02, 2.22548470e-02],\n",
       "          ...,\n",
       "          [3.87087673e-01, 3.32185715e-01, 3.24538678e-01],\n",
       "          [3.97939146e-01, 3.45272511e-01, 3.36860776e-01],\n",
       "          [3.85391742e-01, 3.38332921e-01, 3.38332921e-01]]],\n",
       " \n",
       " \n",
       "        [[[6.58823475e-02, 3.05882357e-02, 1.09803928e-02],\n",
       "          [7.21039176e-02, 3.68098058e-02, 1.72019619e-02],\n",
       "          [8.04411694e-02, 5.08333333e-02, 2.83823516e-02],\n",
       "          ...,\n",
       "          [6.55882731e-02, 5.36078848e-02, 3.33235711e-02],\n",
       "          [8.99549276e-02, 7.49470741e-02, 5.43647148e-02],\n",
       "          [1.12549022e-01, 8.50980431e-02, 6.15686253e-02]],\n",
       " \n",
       "         [[1.00000001e-01, 6.47058859e-02, 4.50980403e-02],\n",
       "          [1.04256861e-01, 6.89627454e-02, 4.93549034e-02],\n",
       "          [9.60000008e-02, 6.63921610e-02, 4.39411774e-02],\n",
       "          ...,\n",
       "          [9.43529755e-02, 7.99019933e-02, 5.02059124e-02],\n",
       "          [1.17207870e-01, 9.72882509e-02, 6.80706054e-02],\n",
       "          [1.40784323e-01, 1.13333330e-01, 8.50980431e-02]],\n",
       " \n",
       "         [[1.17647059e-01, 8.23529437e-02, 6.27451017e-02],\n",
       "          [1.22558817e-01, 8.72647017e-02, 6.76568598e-02],\n",
       "          [1.06470592e-01, 7.68627450e-02, 5.44117652e-02],\n",
       "          ...,\n",
       "          [9.57843587e-02, 7.61765093e-02, 3.39216031e-02],\n",
       "          [1.19568646e-01, 9.89902094e-02, 5.42157032e-02],\n",
       "          [1.39215693e-01, 1.13725491e-01, 7.05882385e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4.19607848e-01, 4.39215690e-01, 4.11764711e-01],\n",
       "          [4.21245068e-01, 4.40852910e-01, 4.15039152e-01],\n",
       "          [4.41470474e-01, 4.52548891e-01, 4.34166491e-01],\n",
       "          ...,\n",
       "          [6.98627949e-01, 6.35588765e-01, 5.95000565e-01],\n",
       "          [7.09215939e-01, 6.67372823e-01, 6.46431684e-01],\n",
       "          [6.76470578e-01, 6.41176581e-01, 6.33333445e-01]],\n",
       " \n",
       "         [[4.22352970e-01, 4.41960812e-01, 4.14509833e-01],\n",
       "          [4.20060784e-01, 4.39668626e-01, 4.12217647e-01],\n",
       "          [4.25862700e-01, 4.36941147e-01, 4.15176421e-01],\n",
       "          ...,\n",
       "          [7.44372666e-01, 6.86823726e-01, 6.45000219e-01],\n",
       "          [7.21125484e-01, 6.85419559e-01, 6.67676508e-01],\n",
       "          [6.81176543e-01, 6.55294120e-01, 6.52941287e-01]],\n",
       " \n",
       "         [[4.27058816e-01, 4.46666658e-01, 4.19215679e-01],\n",
       "          [4.20837253e-01, 4.40445095e-01, 4.12994117e-01],\n",
       "          [4.19892162e-01, 4.30970579e-01, 4.09205884e-01],\n",
       "          ...,\n",
       "          [7.52666593e-01, 6.94911718e-01, 6.60235286e-01],\n",
       "          [7.17754900e-01, 6.84401989e-01, 6.68029428e-01],\n",
       "          [6.96470618e-01, 6.72941208e-01, 6.72941208e-01]]],\n",
       " \n",
       " \n",
       "        [[[4.66431379e-01, 3.44862759e-01, 2.74274528e-01],\n",
       "          [4.40552145e-01, 3.18983525e-01, 2.48395294e-01],\n",
       "          [4.50305849e-01, 3.28737229e-01, 2.58148998e-01],\n",
       "          ...,\n",
       "          [3.59313905e-01, 2.73894340e-01, 2.33270839e-01],\n",
       "          [3.13493520e-01, 2.20549211e-01, 1.71315506e-01],\n",
       "          [2.70666659e-01, 1.80470586e-01, 1.25568628e-01]],\n",
       " \n",
       "         [[4.53490198e-01, 3.31921577e-01, 2.61333317e-01],\n",
       "          [4.21828240e-01, 3.00259620e-01, 2.29671374e-01],\n",
       "          [4.25086260e-01, 3.03517640e-01, 2.32929409e-01],\n",
       "          ...,\n",
       "          [3.43525618e-01, 2.61564851e-01, 2.18953118e-01],\n",
       "          [3.11318606e-01, 2.24048808e-01, 1.72009602e-01],\n",
       "          [2.74274528e-01, 1.84313729e-01, 1.29411772e-01]],\n",
       " \n",
       "         [[4.29019600e-01, 3.07450980e-01, 2.36862749e-01],\n",
       "          [3.94380391e-01, 2.72811770e-01, 2.02223524e-01],\n",
       "          [3.94078463e-01, 2.72509813e-01, 2.01921582e-01],\n",
       "          ...,\n",
       "          [3.20882380e-01, 2.38921613e-01, 1.92254961e-01],\n",
       "          [3.05047214e-01, 2.18772709e-01, 1.66733503e-01],\n",
       "          [2.70980388e-01, 1.84705883e-01, 1.29803911e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[7.27450609e-01, 4.90194894e-02, 8.86273533e-02],\n",
       "          [6.92238867e-01, 3.72822173e-02, 7.60312080e-02],\n",
       "          [6.41470253e-01, 3.20783667e-02, 6.18822388e-02],\n",
       "          ...,\n",
       "          [3.71470749e-01, 1.29353046e-01, 1.16980463e-01],\n",
       "          [3.29619914e-01, 7.61805475e-02, 6.83374032e-02],\n",
       "          [2.83529490e-01, 2.98038255e-02, 2.19606888e-02]],\n",
       " \n",
       "         [[7.88627088e-01, 7.67841712e-02, 1.23372369e-01],\n",
       "          [7.48892248e-01, 5.99512570e-02, 9.84665602e-02],\n",
       "          [6.81180239e-01, 3.33215669e-02, 6.02235533e-02],\n",
       "          ...,\n",
       "          [3.48863006e-01, 1.09588504e-01, 1.01117872e-01],\n",
       "          [3.13006461e-01, 7.30848536e-02, 6.89279661e-02],\n",
       "          [2.86039203e-01, 4.61175665e-02, 4.19606827e-02]],\n",
       " \n",
       "         [[8.45960557e-01, 1.16862580e-01, 1.60078287e-01],\n",
       "          [7.94660211e-01, 9.12696794e-02, 1.25897124e-01],\n",
       "          [7.30219424e-01, 6.23488910e-02, 9.15135816e-02],\n",
       "          ...,\n",
       "          [3.99141073e-01, 1.58196002e-01, 1.53419465e-01],\n",
       "          [3.69993538e-01, 1.29009992e-01, 1.31737024e-01],\n",
       "          [3.55450690e-01, 1.20078117e-01, 1.19999662e-01]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[7.03980386e-01, 5.97745121e-01, 3.35176468e-01],\n",
       "          [6.06346905e-01, 5.00111580e-01, 2.32405692e-01],\n",
       "          [5.55446565e-01, 4.42769617e-01, 1.75391182e-01],\n",
       "          ...,\n",
       "          [9.06438231e-01, 7.49778390e-01, 4.67526972e-01],\n",
       "          [9.00127947e-01, 7.46202230e-01, 4.60027814e-01],\n",
       "          [8.87862742e-01, 7.38843143e-01, 4.45078433e-01]],\n",
       " \n",
       "         [[5.75098038e-01, 4.60313708e-01, 2.00960785e-01],\n",
       "          [5.38019955e-01, 4.23235565e-01, 1.59438923e-01],\n",
       "          [5.30381858e-01, 4.13705885e-01, 1.44235283e-01],\n",
       "          ...,\n",
       "          [9.16501462e-01, 7.64677882e-01, 4.86168087e-01],\n",
       "          [9.21240389e-01, 7.72750199e-01, 4.93566483e-01],\n",
       "          [9.22627449e-01, 7.74137259e-01, 4.90509808e-01]],\n",
       " \n",
       "         [[5.39411783e-01, 4.16078418e-01, 1.53333321e-01],\n",
       "          [5.56107819e-01, 4.32774514e-01, 1.68873534e-01],\n",
       "          [5.79360306e-01, 4.53068644e-01, 1.85225502e-01],\n",
       "          ...,\n",
       "          [9.04377401e-01, 7.58460701e-01, 4.93281752e-01],\n",
       "          [9.17676985e-01, 7.74343610e-01, 5.11206388e-01],\n",
       "          [9.28529382e-01, 7.85196126e-01, 5.22058845e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[5.50784290e-01, 3.67352933e-01, 1.45098045e-01],\n",
       "          [5.23685277e-01, 3.39675963e-01, 1.19154885e-01],\n",
       "          [4.94036734e-01, 3.09723020e-01, 9.67818424e-02],\n",
       "          ...,\n",
       "          [9.14723098e-01, 6.63742721e-01, 3.85311335e-01],\n",
       "          [9.02705908e-01, 6.45265162e-01, 3.68930876e-01],\n",
       "          [8.95000041e-01, 6.25294089e-01, 3.52941185e-01]],\n",
       " \n",
       "         [[5.32058716e-01, 3.47745001e-01, 1.28137141e-01],\n",
       "          [5.01581967e-01, 3.17268223e-01, 1.02104127e-01],\n",
       "          [4.70529288e-01, 2.86215574e-01, 7.71753863e-02],\n",
       "          ...,\n",
       "          [9.21508908e-01, 6.64677024e-01, 3.88196170e-01],\n",
       "          [9.10829723e-01, 6.46419048e-01, 3.72915417e-01],\n",
       "          [9.00902033e-01, 6.30313754e-01, 3.59725535e-01]],\n",
       " \n",
       "         [[5.10686219e-01, 3.33862722e-01, 1.10509776e-01],\n",
       "          [4.79862720e-01, 3.03039193e-01, 8.48235041e-02],\n",
       "          [4.51810777e-01, 2.70212233e-01, 6.44024238e-02],\n",
       "          ...,\n",
       "          [9.26392198e-01, 6.68647110e-01, 3.92470658e-01],\n",
       "          [9.15980399e-01, 6.51821494e-01, 3.76080483e-01],\n",
       "          [9.05705869e-01, 6.38862789e-01, 3.60784322e-01]]],\n",
       " \n",
       " \n",
       "        [[[2.55235285e-01, 1.84647053e-01, 1.29745096e-01],\n",
       "          [2.78515697e-01, 2.10450009e-01, 1.49727941e-01],\n",
       "          [3.15102935e-01, 2.36139715e-01, 1.77796558e-01],\n",
       "          ...,\n",
       "          [4.05955881e-01, 3.11421573e-01, 2.17512265e-01],\n",
       "          [3.74250233e-01, 2.81672299e-01, 1.90126806e-01],\n",
       "          [3.39588255e-01, 2.52313703e-01, 1.69627458e-01]],\n",
       " \n",
       "         [[2.62823522e-01, 1.93235278e-01, 1.36333331e-01],\n",
       "          [2.75755405e-01, 2.02352941e-01, 1.43961757e-01],\n",
       "          [3.13823521e-01, 2.34411761e-01, 1.70686260e-01],\n",
       "          ...,\n",
       "          [4.11845565e-01, 3.12825978e-01, 2.21159309e-01],\n",
       "          [3.90676826e-01, 2.95676798e-01, 2.03323916e-01],\n",
       "          [3.74705851e-01, 2.76666641e-01, 1.90392151e-01]],\n",
       " \n",
       "         [[2.89509803e-01, 2.22843140e-01, 1.60098046e-01],\n",
       "          [3.02122533e-01, 2.29377449e-01, 1.67088225e-01],\n",
       "          [3.35931361e-01, 2.54436255e-01, 1.88419119e-01],\n",
       "          ...,\n",
       "          [4.58615214e-01, 3.58345598e-01, 2.65220582e-01],\n",
       "          [4.44573402e-01, 3.46990079e-01, 2.55928814e-01],\n",
       "          [4.28921580e-01, 3.30882341e-01, 2.44607836e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[9.63725373e-02, 1.00294106e-01, 3.75490077e-02],\n",
       "          [8.63431618e-02, 8.41863006e-02, 1.53627675e-02],\n",
       "          [7.74877742e-02, 6.86642453e-02, 3.34560173e-03],\n",
       "          ...,\n",
       "          [1.18627213e-02, 2.04166342e-02, 0.00000000e+00],\n",
       "          [3.87006486e-03, 2.17769537e-02, 2.13976647e-03],\n",
       "          [1.66667858e-03, 2.51960903e-02, 9.50981583e-03]],\n",
       " \n",
       "         [[9.80392173e-02, 1.01960786e-01, 3.92156877e-02],\n",
       "          [8.28431398e-02, 8.06862712e-02, 1.18627418e-02],\n",
       "          [7.71813467e-02, 6.83578178e-02, 1.47058826e-03],\n",
       "          ...,\n",
       "          [1.92132089e-02, 2.90171299e-02, 5.11271181e-03],\n",
       "          [1.06067490e-02, 2.97822375e-02, 7.24256970e-03],\n",
       "          [0.00000000e+00, 1.76863130e-02, 2.00003828e-03]],\n",
       " \n",
       "         [[9.08627957e-02, 9.47843641e-02, 2.48628501e-02],\n",
       "          [8.67901668e-02, 8.46332982e-02, 1.41950790e-02],\n",
       "          [9.23356786e-02, 8.35121498e-02, 1.08896364e-02],\n",
       "          ...,\n",
       "          [2.05882359e-02, 2.59068962e-02, 4.62011434e-03],\n",
       "          [1.21567668e-02, 3.16896029e-02, 9.92494356e-03],\n",
       "          [0.00000000e+00, 1.92744844e-02, 3.58820893e-03]]],\n",
       " \n",
       " \n",
       "        [[[8.58431384e-02, 8.19215626e-02, 1.13294117e-01],\n",
       "          [1.03019610e-01, 9.90980417e-02, 1.30470589e-01],\n",
       "          [1.13686271e-01, 1.11921564e-01, 1.43294126e-01],\n",
       "          ...,\n",
       "          [2.51783431e-01, 1.82959884e-01, 1.49038270e-01],\n",
       "          [2.30451047e-01, 1.62725583e-01, 1.38451025e-01],\n",
       "          [2.13274509e-01, 1.42686263e-01, 1.26999989e-01]],\n",
       " \n",
       "         [[7.77843073e-02, 7.38627389e-02, 1.03941180e-01],\n",
       "          [9.40160826e-02, 9.00945067e-02, 1.20172940e-01],\n",
       "          [1.04333334e-01, 1.02212742e-01, 1.32291183e-01],\n",
       "          ...,\n",
       "          [2.76268691e-01, 2.06151038e-01, 1.71873555e-01],\n",
       "          [2.57686347e-01, 1.89190865e-01, 1.64392203e-01],\n",
       "          [2.40509808e-01, 1.70568630e-01, 1.52941182e-01]],\n",
       " \n",
       "         [[7.45098069e-02, 7.05882385e-02, 9.41176489e-02],\n",
       "          [8.35990161e-02, 7.96774477e-02, 1.03206858e-01],\n",
       "          [9.00882334e-02, 8.61666650e-02, 1.09696075e-01],\n",
       "          ...,\n",
       "          [2.74902016e-01, 1.97534338e-01, 1.58813700e-01],\n",
       "          [2.60212839e-01, 1.88607886e-01, 1.58795133e-01],\n",
       "          [2.43823528e-01, 1.77156866e-01, 1.49705872e-01]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1.10784490e-02, 2.46078484e-02, 2.63725426e-02],\n",
       "          [1.02911899e-02, 2.38205884e-02, 2.55852826e-02],\n",
       "          [1.37205962e-02, 2.29362715e-02, 2.21666619e-02],\n",
       "          ...,\n",
       "          [7.76372626e-02, 8.84116516e-02, 3.91028412e-02],\n",
       "          [7.81626999e-02, 1.14022411e-01, 5.95547855e-02],\n",
       "          [8.80392045e-02, 1.41862720e-01, 8.08823258e-02]],\n",
       " \n",
       "         [[4.56863083e-03, 2.02549063e-02, 2.41764747e-02],\n",
       "          [4.56863083e-03, 2.02549063e-02, 2.41764747e-02],\n",
       "          [1.06833344e-02, 2.20558848e-02, 2.16637254e-02],\n",
       "          ...,\n",
       "          [9.30676237e-02, 1.11933202e-01, 7.32606724e-02],\n",
       "          [9.92761850e-02, 1.41782388e-01, 9.52334031e-02],\n",
       "          [1.13117620e-01, 1.68019578e-01, 1.15745068e-01]],\n",
       " \n",
       "         [[2.15687469e-04, 2.33137235e-02, 2.35294122e-02],\n",
       "          [2.15687469e-04, 2.33137235e-02, 2.35294122e-02],\n",
       "          [4.64804098e-03, 2.34323516e-02, 2.54490189e-02],\n",
       "          ...,\n",
       "          [9.68087539e-02, 1.20689064e-01, 8.93959478e-02],\n",
       "          [1.13450341e-01, 1.55900687e-01, 1.19058155e-01],\n",
       "          [1.25058815e-01, 1.76254898e-01, 1.36392146e-01]]]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataset.take(1)))\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6ebc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoints/face_effnet_weights_{epoch:02d}.h5'\n",
    "\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,  # Set to False to save the entire model     # Set to False to save the model after every epoch regardless of performance\n",
    "    verbose=1                 # Logs a message whenever a model is save9d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7baf352-6412-41ed-8e49-202f96a71ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.1447\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.2219\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0663\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1794\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0272\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0096\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0195\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0200\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2049\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0000e+00\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0000e+00\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5808/374225900.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                    )\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m siam_model.fit(batch, \n\u001b[0m\u001b[1;32m      5\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                \u001b[0;31m#callbacks=[model_checkpoint_callback]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "siam_model.compile(optimizer=keras.optimizers.Adam(0.001), \n",
    "                   )\n",
    "\n",
    "siam_model.fit(batch, \n",
    "               epochs=20,\n",
    "               #callbacks=[model_checkpoint_callback]\n",
    "               )\n",
    "\n",
    "#embedding_model.save(\"embeddings_face_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a0f91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "embedding_model.save(\"embeddings_face_4ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed4f0fb4-53fd-4f20-a63e-6a4e62a816b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 848ms/step\n",
      "1/1 [==============================] - 1s 842ms/step\n"
     ]
    }
   ],
   "source": [
    "anch_embds = embedding_model.predict(batch[0])\n",
    "pos_embds = embedding_model.predict(batch[1])\n",
    "neg_embds = embedding_model.predict(batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5c58f9e-0738-4492-b3fe-8142b4e8684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.9985318, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9810132, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cossim = keras.metrics.CosineSimilarity()\n",
    "\n",
    "i = 22\n",
    "\n",
    "pos_sim = cossim(anch_embds[i], pos_embds[i])\n",
    "neg_sim = cossim(anch_embds[i], neg_embds[i])\n",
    "\n",
    "print(pos_sim)\n",
    "print(neg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc071f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9879217>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b37e32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.97815406>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8999eaa3-51b3-441c-bc6b-c0a39be12855",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = tf.reduce_mean(tf.square(anch_embds - pos_embds), axis=-1)\n",
    "\n",
    "d_n = tf.reduce_mean(tf.square(anch_embds - neg_emds), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f32d3ce2-569c-4ccc-a3bc-af5c64eb6d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93990636"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(anch_embds[2] - pos_embds[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b5f7ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96476966"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(anch_embds[2] - neg_embds[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "894c712e-14ed-40fb-9cf5-7a2353b4bf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0011390793>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_n[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2a1148d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.94077945>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de25e667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.95942974>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c831ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.003309095>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(d_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d473be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.220223  ,  -4.094585  ,   1.8616943 ,  -4.730528  ,\n",
       "         1.7199237 ,  -2.9923196 ,  -0.71765304,   3.2444282 ,\n",
       "        -1.4946157 ,   2.9306054 ,  -5.7649603 ,  -4.2568016 ,\n",
       "        -2.8130176 ,  -5.20363   ,   5.2181096 ,  -4.2942576 ,\n",
       "        -3.0595117 ,  -6.4208937 ,   8.628557  ,  -0.35944593,\n",
       "         5.250349  ,  -0.55359447,  -1.166327  ,   2.8359075 ,\n",
       "         3.9243643 ,  -7.1290317 ,  -0.22900014,  -0.8546556 ,\n",
       "         7.6698065 ,   1.4251083 ,   7.000401  , -10.723488  ,\n",
       "        -3.4239972 ,  -1.5374297 ,   3.4793866 ,   2.0072205 ,\n",
       "         2.8157723 ,   3.6379566 ,  -7.204947  ,  -0.2722483 ,\n",
       "         0.492214  ,   1.0479809 ,   1.3769054 ,   3.7842267 ,\n",
       "        -5.194569  ,  -5.696434  ,  -5.8673477 ,  -0.28007028,\n",
       "        -5.3335047 ,   4.3239017 ,  -3.2170706 ,  -2.607987  ,\n",
       "         1.2778978 ,   6.908159  ,  -2.8113675 ,   4.5870624 ,\n",
       "        -0.03847475,   1.0731807 ,   3.2307303 ,  -7.840382  ,\n",
       "        -7.1091623 ,   5.9417615 ,   8.099527  ,  -1.9652549 ,\n",
       "         2.3991504 ,   6.436373  ,  -1.2154537 ,   4.4140596 ,\n",
       "        10.622874  ,  -3.031032  ,   4.7860885 ,  -1.6951219 ,\n",
       "        -4.249203  ,   3.1309378 ,  -1.5386379 ,   1.9333984 ,\n",
       "        -1.4518034 ,   8.3152275 ,   2.9096692 ,  -4.640608  ,\n",
       "        -0.20408575,  -0.47197077,  -4.6767745 ,   0.43355194,\n",
       "         2.0755513 ,  -0.28139237,   0.08720096,  -4.4151626 ,\n",
       "         6.04219   ,   1.1066502 ,   8.642194  ,  -7.6990685 ,\n",
       "        -4.2878265 ,   1.2103091 ,   1.2037954 ,  -6.07459   ,\n",
       "        -1.3388199 ,  -2.3512297 ,  -9.327229  ,  -2.5330558 ,\n",
       "         1.1359525 ,  -3.7432253 , -11.605644  ,   6.520144  ,\n",
       "         3.3553717 ,   6.3044715 ,   1.188536  ,   1.036239  ,\n",
       "         1.1425467 ,   1.7334285 ,  11.820596  ,   2.5846527 ,\n",
       "         1.6059904 ,   8.7520895 ,  -2.376595  ,  -4.78711   ,\n",
       "         7.0881333 ,  -5.192432  ,  -3.964476  ,   0.05378243,\n",
       "         1.3343682 ,  -7.23666   ,  -3.7918108 ,  -0.7538253 ,\n",
       "         4.8527975 ,  -2.9749029 ,  -4.8471403 ,  -2.1326377 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(.pos_embds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750db4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
